{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 Huh? What does hotio do? I build and maintain Docker images. When joining the Discord server you'll get access to the #image-builds channel and you can keep an eye on when your favorite app has released a new update. All the updating of docker images is automated, giving you the fastest updates. We're not just building them and pushing them out though...no, every app is tested and when they fail the test, pushing to the registries is cancelled. This for the most part ensures your system remains operational when you are doing auto-updates and are not paying attention. The images get pushed to Docker Hub and GitHub Container Registry . They can then be pulled from Docker Hub with docker pull hotio/... and from GitHub Container Registry with docker pull ghcr.io/hotio/... . On this website you'll also find all the documentation needed to get the containers running. All commands provided include the most basic to get the container running. In most cases you'll have to add additional volumes to get access to your other files that every app needs. Almost all the commands will start with docker run -rm ... , which is the same as docker create , followed by docker start . The argument --rm will make sure that when we exit the container, it'll get deleted. As you might have guessed, these command are not suited for longterm use. For that we suggest to maybe use docker-compose or integrate the commands with systemd . Images where you see a mention of ENTRYPOINT are meant to be used like any other cli app, except that they are containerized. Support \u00b6 Join us on Discord! Donations \u00b6 If you like what I do, you know the drill... GitHub Sponsors Open Collective Nano Bitcoin Litecoin","title":"Home"},{"location":"#introduction","text":"Huh? What does hotio do? I build and maintain Docker images. When joining the Discord server you'll get access to the #image-builds channel and you can keep an eye on when your favorite app has released a new update. All the updating of docker images is automated, giving you the fastest updates. We're not just building them and pushing them out though...no, every app is tested and when they fail the test, pushing to the registries is cancelled. This for the most part ensures your system remains operational when you are doing auto-updates and are not paying attention. The images get pushed to Docker Hub and GitHub Container Registry . They can then be pulled from Docker Hub with docker pull hotio/... and from GitHub Container Registry with docker pull ghcr.io/hotio/... . On this website you'll also find all the documentation needed to get the containers running. All commands provided include the most basic to get the container running. In most cases you'll have to add additional volumes to get access to your other files that every app needs. Almost all the commands will start with docker run -rm ... , which is the same as docker create , followed by docker start . The argument --rm will make sure that when we exit the container, it'll get deleted. As you might have guessed, these command are not suited for longterm use. For that we suggest to maybe use docker-compose or integrate the commands with systemd . Images where you see a mention of ENTRYPOINT are meant to be used like any other cli app, except that they are containerized.","title":"Introduction"},{"location":"#support","text":"Join us on Discord!","title":"Support"},{"location":"#donations","text":"If you like what I do, you know the drill... GitHub Sponsors Open Collective Nano Bitcoin Litecoin","title":"Donations"},{"location":"arr-discord-notifier/","text":"GitHub Arr Discord Notifier sends pretty notifications to a discord webhook. The Radarr and Sonarr v3 (only v3 is supported) docker images come bundled with this script, but it can also be used on its own. Configuration \u00b6 Add a Custom Script to the Connect settings in Sonarr/Radarr as seen below. Then add the environment variable DISCORD_WEBHOOK with your webhook url provided by Discord to the container. After that hit the Test button and you should see a notification appear in your discord channel. If you also configure the environment variable TMDB_API_KEY , when possible it will use an episode still as a backdrop image and add a Cast field. If you want to hide some fields, you can use DROP_FIELDS=\"backdrop overview release airdate\" as a variable, all field names in lowercase, backdrop and poster are valid values too. Sending to multiple webhooks can be done with additional variables like DISCORD_WEBHOOK_0 and DROP_FIELDS_0 . By default the hostname is used as the Author of the notification, you can modify this by changing the hostname or the variable AUTHOR_NAME . Sample images \u00b6","title":"Arr Discord Notifier"},{"location":"arr-discord-notifier/#configuration","text":"Add a Custom Script to the Connect settings in Sonarr/Radarr as seen below. Then add the environment variable DISCORD_WEBHOOK with your webhook url provided by Discord to the container. After that hit the Test button and you should see a notification appear in your discord channel. If you also configure the environment variable TMDB_API_KEY , when possible it will use an episode still as a backdrop image and add a Cast field. If you want to hide some fields, you can use DROP_FIELDS=\"backdrop overview release airdate\" as a variable, all field names in lowercase, backdrop and poster are valid values too. Sending to multiple webhooks can be done with additional variables like DISCORD_WEBHOOK_0 and DROP_FIELDS_0 . By default the hostname is used as the Author of the notification, you can modify this by changing the hostname or the variable AUTHOR_NAME .","title":"Configuration"},{"location":"arr-discord-notifier/#sample-images","text":"","title":"Sample images"},{"location":"custom-scripts/","text":"This will only work for containers using s6 overlay , recognisable by ENVIRONMENT printed at the top of the log when the container starts. If you have a need to do additional stuff when the container starts or stops, you can mount your script with the volume /docker/host/my-script.sh:/etc/cont-init.d/99-my-script to execute your script on container start or /docker/host/my-script.sh:/etc/cont-finish.d/99-my-script to execute it when the container stops. An example script can be seen below. 1 2 3 #!/usr/bin/with-contenv bash echo \"Hello, this is me, your script.\"","title":"Custom scripts"},{"location":"faq/","text":"Troubleshooting \u00b6 Someone asked you for a 'docker-compose' snippet...How do you give them that? If you are not using docker-compose that can sound like a daunting task. Have no fear though, the following cli command spits it out. docker run --rm -v /var/run/docker.sock:/var/run/docker.sock:ro red5d/docker-autocompose <container-name-or-id> [ <additional-names-or-ids> ] Now you should upload this to something like hastebin.com , pastebin.com , github.com or any other site that provides easy sharing of text files. If you are sure that there's no personal information to be seen, you can also use the command below and provide them the link. docker run --rm -v /var/run/docker.sock:/var/run/docker.sock:ro red5d/docker-autocompose <container-name-or-id> [ <additional-names-or-ids> ] | curl -H \"x-uuid;\" --upload-file - 'https://paste.c-net.org/' Installation \u00b6 How do I install 'docker-compose' on my machine? There's all sorts of ways to do this, here we are going to pick the easy way. The following commands will download and install a wrapper script that uses the docker image linuxserver/docker-compose . sudo curl -fsSL https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh > /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose Now you should be able to do docker-compose --version as if it were natively installed. This script doesn't pull for the latest image though everytime it runs, so it might be a good idea to once in a while purge the image. It'll then pull a new one the next time it runs. Installing Docker, how and where? I'd have a look at the official Docker Engine installation instructions. Guides \u00b6 Got any Docker guides? Take a look here for an extensive guide on best practises from the *arr team. But, but, how do I configure all this stuff? Maybe TRaSH from TRaSH Guides can help...","title":"FAQ"},{"location":"faq/#troubleshooting","text":"Someone asked you for a 'docker-compose' snippet...How do you give them that? If you are not using docker-compose that can sound like a daunting task. Have no fear though, the following cli command spits it out. docker run --rm -v /var/run/docker.sock:/var/run/docker.sock:ro red5d/docker-autocompose <container-name-or-id> [ <additional-names-or-ids> ] Now you should upload this to something like hastebin.com , pastebin.com , github.com or any other site that provides easy sharing of text files. If you are sure that there's no personal information to be seen, you can also use the command below and provide them the link. docker run --rm -v /var/run/docker.sock:/var/run/docker.sock:ro red5d/docker-autocompose <container-name-or-id> [ <additional-names-or-ids> ] | curl -H \"x-uuid;\" --upload-file - 'https://paste.c-net.org/'","title":"Troubleshooting"},{"location":"faq/#installation","text":"How do I install 'docker-compose' on my machine? There's all sorts of ways to do this, here we are going to pick the easy way. The following commands will download and install a wrapper script that uses the docker image linuxserver/docker-compose . sudo curl -fsSL https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh > /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose Now you should be able to do docker-compose --version as if it were natively installed. This script doesn't pull for the latest image though everytime it runs, so it might be a good idea to once in a while purge the image. It'll then pull a new one the next time it runs. Installing Docker, how and where? I'd have a look at the official Docker Engine installation instructions.","title":"Installation"},{"location":"faq/#guides","text":"Got any Docker guides? Take a look here for an extensive guide on best practises from the *arr team. But, but, how do I configure all this stuff? Maybe TRaSH from TRaSH Guides can help...","title":"Guides"},{"location":"libseccomp2-saga/","text":"Hello there! So somebody linked you this page or you found it by either pure luck or intense Google magic? Good! What is all this libseccomp2 mumbo jumbo about? If you are running Raspbian/Raspberry Pi OS (key part here, it being arm 32-bit), your docker container all of a sudden stops working and you appear to be the only person in the world to have this happen... Rest assured you are not alone. The issue here is that you are probably running an outdated version of libseccomp2. The symptom can vary in many ways depending on the app. Radarr for example does nothing (no error or anything), Mylar3 gives this Fatal Python error: pyinit_main: can't initialize time , Overseerr gives you Fatal error in , line 0 , docker exec <container-name> date returns 1970 and the list goes on. The fastest way to detect if that is indeed your issue is by running the container in --privileged mode (I understand that you are not comfortable with this, and you should avoid running privileged at all costs), if it works after doing this, you now know you're a victim too. If you really don't like doing this, doing docker exec <container-name> date might confirm it too if you are 100% sure your system date is working as expected. Several solutions: Upgrade your OS to Ubuntu 20.04 arm64 image (found here ). Manually update libseccomp2 (found here ). wget http://ftp.us.debian.org/debian/pool/main/libs/libseccomp/libseccomp2_2.5.1-1_armhf.deb sudo dpkg -i libseccomp2_2.5.1-1_armhf.deb Keep running with --privileged , not recommended though. The prefered way here is going with Ubuntu + ARM64 if you can. Info Make sure you are running the latest Docker Engine .","title":"The libseccomp2 saga"},{"location":"pullio/","text":"GitHub Updating your docker containers the easy way. Pullio is a bash script that you execute with cron, jobber , a systemd timer or any other way that you prefer, it then does a docker-compose pull for all the containers configured to have notifications or updates enabled. It then checks if there's an update available and takes action according to your configuration. As you might have already guessed it, this script relies on docker-compose to do the heavy lifting and thus is only compatible with docker-compose managed containers. Features: Discord notifications (see below for preview) No notifications if you leave the webhook out, it'll run as an updater and script executer Detailed info about what has changed for images that follow the Opencontainers Annotation Keys Execute script before sending notification Execute script before updating container, after container is stopped Private registries With --tag you can use seperate configs for hourly \"Update available\" notifications and on a daily schedule actually apply the updates Installation \u00b6 curl -fsSL \"https://raw.githubusercontent.com/hotio/pullio/master/pullio.sh\" > /usr/local/bin/pullio chmod +x /usr/local/bin/pullio Now execute it however and whenever you want. Configuration \u00b6 You configure the script its behaviour by adding one or more of the following labels to your docker-compose.yml for every container you want. Adding no discord webhook will disable the notifications. ... labels: - \"org.hotio.pullio.notify=true\" - \"org.hotio.pullio.update=true\" - \"org.hotio.pullio.discord.webhook=https://discord.com/api/webhooks/...\" - \"org.hotio.pullio.generic.webhook=https://some.domain.com/api/webhooks/...\" - \"org.hotio.pullio.author.avatar=https://domain.com/logo.png\" - \"org.hotio.pullio.script.notify=bash /notify-script.sh\" - \"org.hotio.pullio.script.update=bash /update-script.sh\" - \"org.hotio.pullio.registry.authfile=/authfile.txt\" Using --tag mytag , would let you do the following. ... labels: - \"org.hotio.pullio.mytag.notify=true\" - \"org.hotio.pullio.mytag.discord.webhook=https://discord.com/api/webhooks/...\" If you need to provide credentials for a Private Registry, this file's content needs to be as shown below. { \"registry\": \"ghcr.io\", \"username\": \"your_username\", \"password\": \"your_password\" } Notification preview \u00b6","title":"Pullio"},{"location":"pullio/#installation","text":"curl -fsSL \"https://raw.githubusercontent.com/hotio/pullio/master/pullio.sh\" > /usr/local/bin/pullio chmod +x /usr/local/bin/pullio Now execute it however and whenever you want.","title":"Installation"},{"location":"pullio/#configuration","text":"You configure the script its behaviour by adding one or more of the following labels to your docker-compose.yml for every container you want. Adding no discord webhook will disable the notifications. ... labels: - \"org.hotio.pullio.notify=true\" - \"org.hotio.pullio.update=true\" - \"org.hotio.pullio.discord.webhook=https://discord.com/api/webhooks/...\" - \"org.hotio.pullio.generic.webhook=https://some.domain.com/api/webhooks/...\" - \"org.hotio.pullio.author.avatar=https://domain.com/logo.png\" - \"org.hotio.pullio.script.notify=bash /notify-script.sh\" - \"org.hotio.pullio.script.update=bash /update-script.sh\" - \"org.hotio.pullio.registry.authfile=/authfile.txt\" Using --tag mytag , would let you do the following. ... labels: - \"org.hotio.pullio.mytag.notify=true\" - \"org.hotio.pullio.mytag.discord.webhook=https://discord.com/api/webhooks/...\" If you need to provide credentials for a Private Registry, this file's content needs to be as shown below. { \"registry\": \"ghcr.io\", \"username\": \"your_username\", \"password\": \"your_password\" }","title":"Configuration"},{"location":"pullio/#notification-preview","text":"","title":"Notification preview"},{"location":"tags-overview/","text":"For the most part you can use the tags release , testing and nightly . You can also use tags that reference a commit or version number, for example release-1.0.0 , nightly-95522985ff8b6aa014e44b4901bfd835837c6d76 or testing-de64d54 . A long git sha refers to a git sha from the app, a short one refers to a git sha from the image repository. Have a look below to see the available tags for each image and their current version status. Apps \u00b6 hotio/apprise \u00b6 Tag Upstream Version Build release (latest) GitHub releases hotio/autoscan \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master hotio/bazarr \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to development branch hotio/borg \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases hotio/cloudflareddns \u00b6 Tag Description Build release (latest) The main branch hotio/conreq \u00b6 Tag Description Version Build release (latest) main branch nightly develop branch hotio/crop \u00b6 Tag Description Version Build release (latest) GitHub releases nightly Every commit to develop branch hotio/duplicacy \u00b6 Tag Upstream Version Build release (latest) Stable channel testing Latest channel hotio/hdidle \u00b6 Tag Upstream Version Build release (latest) GitHub releases hotio/jackett \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases hotio/jellyfin \u00b6 Tag Upstream Version Build release (latest) Releases testing Release Candidates nightly Every commit to master branch hotio/lidarr \u00b6 Tag Upstream Version Build release (latest) master testing develop nightly nightly hotio/mergerfs \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch hotio/movearr \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch hotio/mylar3 \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to python3-dev branch hotio/nzbget \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases hotio/nzbhydra2 \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases hotio/ombi \u00b6 Tag Upstream Version Build release (latest) v3 releases testing v4 releases hotio/overseerr \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to develop branch hotio/plex \u00b6 Tag Upstream Version Build release (latest) Releases hotio/plexarr \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch hotio/qbittorrent \u00b6 Tag Upstream Version Build release (latest) Stable testing Unstable hotio/qflood \u00b6 Tag Upstream Version Build release (latest) Releases hotio/radarr \u00b6 Tag Upstream Version Build release (latest) master testing develop nightly nightly musl nightly, runs on Alpine hotio/rar2fs \u00b6 Tag Upstream Version Build release (latest) GitHub releases hotio/rclone \u00b6 Tag Upstream Version Build release (latest) Releases testing Beta releases hotio/readarr \u00b6 Tag Upstream Version Build release (latest) not yet available testing not yet available nightly nightly hotio/requestrr \u00b6 Tag Upstream Version Build release (latest) GitHub releases hotio/restic \u00b6 Tag Upstream Version Build release (latest) GitHub releases hotio/rflood \u00b6 Tag Upstream Version Build release (latest) Releases hotio/sabnzbd \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases nightly Every commit to develop branch hotio/scrutiny \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch hotio/sonarr \u00b6 Tag Upstream Version Build release (latest) master testing develop nightly phantom-develop hotio/stash \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly GitHub latest_develop release hotio/tautulli \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases hotio/trackarr \u00b6 Tag Upstream Version Build release (latest) Releases nightly Every commit to develop branch hotio/unpackerr \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases nightly Every commit to master branch Base Images \u00b6 hotio/base \u00b6 Tag Description Build bionic Based on Ubuntu 18.04 focal Based on Ubuntu 20.04 alpine Based on Alpine 3.12 hotio/mono \u00b6 Tag Description Build bionic Based on Ubuntu 18.04 focal Based on Ubuntu 20.04","title":"Tags overview"},{"location":"tags-overview/#apps","text":"","title":"Apps"},{"location":"tags-overview/#hotioapprise","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"hotio/apprise"},{"location":"tags-overview/#hotioautoscan","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master","title":"hotio/autoscan"},{"location":"tags-overview/#hotiobazarr","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to development branch","title":"hotio/bazarr"},{"location":"tags-overview/#hotioborg","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/borg"},{"location":"tags-overview/#hotiocloudflareddns","text":"Tag Description Build release (latest) The main branch","title":"hotio/cloudflareddns"},{"location":"tags-overview/#hotioconreq","text":"Tag Description Version Build release (latest) main branch nightly develop branch","title":"hotio/conreq"},{"location":"tags-overview/#hotiocrop","text":"Tag Description Version Build release (latest) GitHub releases nightly Every commit to develop branch","title":"hotio/crop"},{"location":"tags-overview/#hotioduplicacy","text":"Tag Upstream Version Build release (latest) Stable channel testing Latest channel","title":"hotio/duplicacy"},{"location":"tags-overview/#hotiohdidle","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"hotio/hdidle"},{"location":"tags-overview/#hotiojackett","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/jackett"},{"location":"tags-overview/#hotiojellyfin","text":"Tag Upstream Version Build release (latest) Releases testing Release Candidates nightly Every commit to master branch","title":"hotio/jellyfin"},{"location":"tags-overview/#hotiolidarr","text":"Tag Upstream Version Build release (latest) master testing develop nightly nightly","title":"hotio/lidarr"},{"location":"tags-overview/#hotiomergerfs","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch","title":"hotio/mergerfs"},{"location":"tags-overview/#hotiomovearr","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch","title":"hotio/movearr"},{"location":"tags-overview/#hotiomylar3","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to python3-dev branch","title":"hotio/mylar3"},{"location":"tags-overview/#hotionzbget","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/nzbget"},{"location":"tags-overview/#hotionzbhydra2","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/nzbhydra2"},{"location":"tags-overview/#hotioombi","text":"Tag Upstream Version Build release (latest) v3 releases testing v4 releases","title":"hotio/ombi"},{"location":"tags-overview/#hotiooverseerr","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to develop branch","title":"hotio/overseerr"},{"location":"tags-overview/#hotioplex","text":"Tag Upstream Version Build release (latest) Releases","title":"hotio/plex"},{"location":"tags-overview/#hotioplexarr","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch","title":"hotio/plexarr"},{"location":"tags-overview/#hotioqbittorrent","text":"Tag Upstream Version Build release (latest) Stable testing Unstable","title":"hotio/qbittorrent"},{"location":"tags-overview/#hotioqflood","text":"Tag Upstream Version Build release (latest) Releases","title":"hotio/qflood"},{"location":"tags-overview/#hotioradarr","text":"Tag Upstream Version Build release (latest) master testing develop nightly nightly musl nightly, runs on Alpine","title":"hotio/radarr"},{"location":"tags-overview/#hotiorar2fs","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"hotio/rar2fs"},{"location":"tags-overview/#hotiorclone","text":"Tag Upstream Version Build release (latest) Releases testing Beta releases","title":"hotio/rclone"},{"location":"tags-overview/#hotioreadarr","text":"Tag Upstream Version Build release (latest) not yet available testing not yet available nightly nightly","title":"hotio/readarr"},{"location":"tags-overview/#hotiorequestrr","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"hotio/requestrr"},{"location":"tags-overview/#hotiorestic","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"hotio/restic"},{"location":"tags-overview/#hotiorflood","text":"Tag Upstream Version Build release (latest) Releases","title":"hotio/rflood"},{"location":"tags-overview/#hotiosabnzbd","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases nightly Every commit to develop branch","title":"hotio/sabnzbd"},{"location":"tags-overview/#hotioscrutiny","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch","title":"hotio/scrutiny"},{"location":"tags-overview/#hotiosonarr","text":"Tag Upstream Version Build release (latest) master testing develop nightly phantom-develop","title":"hotio/sonarr"},{"location":"tags-overview/#hotiostash","text":"Tag Upstream Version Build release (latest) GitHub releases nightly GitHub latest_develop release","title":"hotio/stash"},{"location":"tags-overview/#hotiotautulli","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/tautulli"},{"location":"tags-overview/#hotiotrackarr","text":"Tag Upstream Version Build release (latest) Releases nightly Every commit to develop branch","title":"hotio/trackarr"},{"location":"tags-overview/#hotiounpackerr","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases nightly Every commit to master branch","title":"hotio/unpackerr"},{"location":"tags-overview/#base-images","text":"","title":"Base Images"},{"location":"tags-overview/#hotiobase","text":"Tag Description Build bionic Based on Ubuntu 18.04 focal Based on Ubuntu 20.04 alpine Based on Alpine 3.12","title":"hotio/base"},{"location":"tags-overview/#hotiomono","text":"Tag Description Build bionic Based on Ubuntu 18.04 focal Based on Ubuntu 20.04","title":"hotio/mono"},{"location":"containers/apprise/","text":"GitHub GitHub Registry Docker Hub Apprise Starting the container \u00b6 cli docker run --rm hotio/apprise ... The default ENTRYPOINT is apprise . Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases","title":"hotio/apprise"},{"location":"containers/apprise/#starting-the-container","text":"cli docker run --rm hotio/apprise ... The default ENTRYPOINT is apprise .","title":"Starting the container"},{"location":"containers/apprise/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"Tags"},{"location":"containers/autoscan/","text":"GitHub GitHub Registry Docker Hub Autoscan Starting the container \u00b6 cli docker run --rm \\ --name autoscan \\ -p 3030 :3030 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e PLEX_LOGIN = \"\" \\ -e PLEX_PASSWORD = \"\" \\ -v /<host_folder_config>:/config \\ hotio/autoscan compose version : \"3.7\" services : autoscan : container_name : autoscan image : hotio/autoscan ports : - \"3030:3030\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - PLEX_LOGIN - PLEX_PASSWORD volumes : - /<host_folder_config>:/config If PLEX_LOGIN + PLEX_PASSWORD are not empty and the file /config/plex.token does not exist, an attempt is made to get a Plex token for Autoscan. Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master Using a secure Plex connection \u00b6 If you want to keep using secure connections within Plex, but don't wanna buy your own domain and keep the connection between Autoscan and Plex inside of their Docker network. Follow the below procedure. Go to https://plex.tv/pms/resources.xml?includeHttps=1&X-Plex-Token=xxxxxxxxxxxxxx (replace xxxxxxxxxxxxxx with your token) and look for a url that looks like https://10-1-0-100.xxxxxxxxxxxxx.plex.direct:32400 . That url can be used in your Autoscan plex target. You should however give the Plex container a static IP if you don't wanna do this every 5 minutes.","title":"hotio/autoscan"},{"location":"containers/autoscan/#starting-the-container","text":"cli docker run --rm \\ --name autoscan \\ -p 3030 :3030 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e PLEX_LOGIN = \"\" \\ -e PLEX_PASSWORD = \"\" \\ -v /<host_folder_config>:/config \\ hotio/autoscan compose version : \"3.7\" services : autoscan : container_name : autoscan image : hotio/autoscan ports : - \"3030:3030\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - PLEX_LOGIN - PLEX_PASSWORD volumes : - /<host_folder_config>:/config If PLEX_LOGIN + PLEX_PASSWORD are not empty and the file /config/plex.token does not exist, an attempt is made to get a Plex token for Autoscan.","title":"Starting the container"},{"location":"containers/autoscan/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master","title":"Tags"},{"location":"containers/autoscan/#using-a-secure-plex-connection","text":"If you want to keep using secure connections within Plex, but don't wanna buy your own domain and keep the connection between Autoscan and Plex inside of their Docker network. Follow the below procedure. Go to https://plex.tv/pms/resources.xml?includeHttps=1&X-Plex-Token=xxxxxxxxxxxxxx (replace xxxxxxxxxxxxxx with your token) and look for a url that looks like https://10-1-0-100.xxxxxxxxxxxxx.plex.direct:32400 . That url can be used in your Autoscan plex target. You should however give the Plex container a static IP if you don't wanna do this every 5 minutes.","title":"Using a secure Plex connection"},{"location":"containers/base/","text":"GitHub GitHub Registry Docker Hub Tags \u00b6 Tag Description Build bionic Based on Ubuntu 18.04 focal Based on Ubuntu 20.04 alpine Based on Alpine 3.12","title":"hotio/base"},{"location":"containers/base/#tags","text":"Tag Description Build bionic Based on Ubuntu 18.04 focal Based on Ubuntu 20.04 alpine Based on Alpine 3.12","title":"Tags"},{"location":"containers/bazarr/","text":"GitHub GitHub Registry Docker Hub Bazarr Starting the container \u00b6 cli docker run --rm \\ --name bazarr \\ -p 6767 :6767 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/bazarr compose version : \"3.7\" services : bazarr : container_name : bazarr image : hotio/bazarr ports : - \"6767:6767\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to development branch","title":"hotio/bazarr"},{"location":"containers/bazarr/#starting-the-container","text":"cli docker run --rm \\ --name bazarr \\ -p 6767 :6767 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/bazarr compose version : \"3.7\" services : bazarr : container_name : bazarr image : hotio/bazarr ports : - \"6767:6767\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/bazarr/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to development branch","title":"Tags"},{"location":"containers/borg/","text":"GitHub GitHub Registry Docker Hub Borg Starting the container \u00b6 cli docker run --rm hotio/borg ... The default ENTRYPOINT is borg . Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/borg"},{"location":"containers/borg/#starting-the-container","text":"cli docker run --rm hotio/borg ... The default ENTRYPOINT is borg .","title":"Starting the container"},{"location":"containers/borg/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"Tags"},{"location":"containers/cloudflareddns/","text":"GitHub GitHub Registry Docker Hub Starting the container \u00b6 cli docker run --rm \\ --name cloudflareddns \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e INTERVAL = 300 \\ -e DETECTION_MODE = \"dig-whoami.cloudflare\" \\ -e LOG_LEVEL = 3 \\ -e cloudflareddns = \"\" \\ -e CF_USER = \"your.cf.email@example.com\" \\ -e CF_APIKEY = \"your.global.apikey\" \\ -e CF_APITOKEN = \"\" \\ -e CF_APITOKEN_ZONE = \"\" \\ -e CF_HOSTS = \"test.example.com;test.foobar.com;test2.foobar.com\" \\ -e CF_ZONES = \"example.com;foobar.com;foobar.com\" \\ -e CF_RECORDTYPES = \"A;A;AAAA\" \\ -v /<host_folder_config>:/config \\ hotio/cloudflareddns compose version : \"3.7\" services : cloudflareddns : container_name : cloudflareddns image : hotio/cloudflareddns environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - INTERVAL=300 - DETECTION_MODE=dig-whoami.cloudflare - LOG_LEVEL=3 - cloudflareddns - CF_USER=your.cf.email@example.com - CF_APIKEY=your.global.apikey - CF_APITOKEN - CF_APITOKEN_ZONE - CF_HOSTS=test.example.com;test.foobar.com;test2.foobar.com - CF_ZONES=example.com;foobar.com;foobar.com - CF_RECORDTYPES=A;A;AAAA volumes : - /<host_folder_config>:/config Possible values for DETECTION_MODE are dig-google.com , dig-opendns.com , dig-whoami.cloudflare , curl-icanhazip.com , curl-wtfismyip.com , curl-showmyip.ca , curl-da.gd , curl-seeip.org and curl-ifconfig.co . If you want to get the local ip from a network interface, use something like local:eth0 as DETECTION_MODE . Notice that we give 3 values each time for CF_HOSTS , CF_ZONES and CF_RECORDTYPES . In our example, the domain test.foobar.com belonging to the zone foobar.com will have its A record updated with an ipv4 ip. If you use CF_APITOKEN , you can leave CF_USER and CF_APIKEY empty. IMPORTANT: All the domain names in CF_HOSTS should have properly configured DNS records on Cloudflare, they will not be created. Tags \u00b6 Tag Description Build release (latest) The main branch Zone ID \u00b6 Instead of the zone_name , you can also fill in a zone_id in CF_ZONES . When using a zone_id , you can use a scoped token ( CF_APITOKEN ) that only needs the Zone - DNS - Edit permissions. This improves security. The configuration could look like the example below. -e CF_APITOKEN = \"azkqvJ86wEScojvSJC8DyY67TwqNwZCtomEVrHwt\" -e CF_HOSTS = \"example.com;test.foobar.com\" -e CF_ZONES = \"zbpsi9ceikrdnnym27s2xnp6s5dvj6ep;dccbe6grakumohwwd4amh4o46yupepn8\" -e CF_RECORDTYPES = \"A;A\" Seperate API Tokens \u00b6 If you do not prefer to use a zone_id , but prefer some more security, you can use 2 seperate tokens. CF_APITOKEN configured with: Permissions Zone - DNS - Edit Zone Resources Include - Specific zone - example.com Include - Specific zone - foobar.com CF_APITOKEN_ZONE configured with: Permissions Zone - Zone - Read Zone Resources Include - All zones Leaving CF_APITOKEN_ZONE blank would mean that only CF_APITOKEN will be used and thus that token should have all required permissions. Which usually means that the token could edit all zones or not be able to fetch the zone_id from the zone_name . Configuration combination examples \u00b6 Below are some example configuration combinations, ordered from most secure to least secure. We use a zone_id so that our token only needs the permissions Zone - DNS - Edit . -e CF_APITOKEN = \"azkqvJ86wEScojvSJC8DyY67TwqNwZCtomEVrHwt\" -e CF_HOSTS = \"vpn.example.com;test.foobar.com\" -e CF_ZONES = \"zbpsi9ceikrdnnym27s2xnp6s5dvj6ep;axozor886pyja7nmbcvu5kh7dp9557j4\" -e CF_RECORDTYPES = \"A;A\" We use additionally a CF_APITOKEN_ZONE with the permissions Zone - Zone - Read to query the zones and getting the zone_id . -e CF_APITOKEN = \"azkqvJ86wEScojvSJC8DyY67TwqNwZCtomEVrHwt\" -e CF_APITOKEN_ZONE = \"8m4TxzWb9QHXEpTwQDMugkKuHRavsxoK8qmJ4P7M\" -e CF_HOSTS = \"vpn.example.com;test.foobar.com\" -e CF_ZONES = \"example.com;axozor886pyja7nmbcvu5kh7dp9557j4\" -e CF_RECORDTYPES = \"A;A\" We use only CF_APITOKEN , but with the permissions Zone - DNS - Edit and Zone - Zone - Read . -e CF_APITOKEN = \"azkqvJ86wEScojvSJC8DyY67TwqNwZCtomEVrHwt\" -e CF_HOSTS = \"vpn.example.com;test.foobar.com\" -e CF_ZONES = \"example.com;axozor886pyja7nmbcvu5kh7dp9557j4\" -e CF_RECORDTYPES = \"A;A\" We use CF_USER and CF_APIKEY , basically giving full control over our account. -e CF_USER = \"your.cf.email@example.com\" -e CF_APIKEY = \"your.global.apikey\" -e CF_HOSTS = \"vpn.example.com;test.foobar.com\" -e CF_ZONES = \"example.com;axozor886pyja7nmbcvu5kh7dp9557j4\" -e CF_RECORDTYPES = \"A;A\" Example of the log output \u00b6 2020-05-17 17:20:54 - INFO - IPv4 detected by [dig-whoami.cloudflare] is [1.1.1.1]. 2020-05-17 17:20:54 - INFO - [1/1] [A] [vpn.example.com] Reading zone list from Cloudflare. 2020-05-17 17:20:54 - INFO - [1/1] [A] [vpn.example.com] Retrieved zone list from Cloudflare. 2020-05-17 17:20:54 - INFO - [1/1] [A] [vpn.example.com] Zone ID [xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx] found for zone [example.com]. 2020-05-17 17:20:54 - INFO - [1/1] [A] [vpn.example.com] Reading DNS record from Cloudflare. 2020-05-17 17:20:55 - INFO - [1/1] [A] [vpn.example.com] Writing DNS record to cache file [/config/cf-ddns-A-vpn.example.com.cache]. 2020-05-17 17:20:55 - INFO - [1/1] [A] [vpn.example.com] Checking if update is needed. 2020-05-17 17:20:55 - INFO - [1/1] [A] [vpn.example.com] No update needed. 2020-05-17 17:20:55 - INFO - Going to sleep for [300] seconds... Log levels \u00b6 For LOG_LEVEL you can pick 0 , 1 , 2 or 3 . 0 will give no log output. It's not recommended to use. 1 will give you the following output types. It's the recommended value when all things are configured and running as expected. UPDATE, WARNING, ERROR 2 will give you the following output types. Use this if you always wanna see what's going on, but 3 gives you too much output. UPDATE, WARNING, ERROR, INFO 3 will give you the following output types. This is the default. UPDATE, WARNING, ERROR, INFO, DEBUG JSON log \u00b6 Every IP update is also logged to /config/cf-ddns-updates.json . This can be used with the Telegraf JSON parser and the tail input, to get your domain updates into InfluxDB. Example output below. { \"domain\" : \"vpn.example.com\" , \"recordtype\" : \"A\" , \"ip\" : \"1.1.1.1\" , \"timestamp\" : \"2020-05-17T20:27:14Z\" } { \"domain\" : \"vpn.example.com\" , \"recordtype\" : \"A\" , \"ip\" : \"1.1.1.1\" , \"timestamp\" : \"2020-05-17T20:29:26Z\" } Cached results from Cloudflare \u00b6 The returned results from Cloudflare are cached. This means minimal api calls to Cloudflare. If you have made any manual changes to the IP on the Cloudflare webinterface, for instance when wanting to test an update, a container restart is needed to clear the cache. The proxy setting (orange cloud) and TTL is also cached and re-set based on the previous value, so if you made any modifications to these settings, you should restart the container so that the script is aware of the new settings. Sending notifications using cloudflareddns \u00b6 You can send notifications when a DNS record gets updated with a new IP using cloudflareddns . Use the environment variable cloudflareddns to configure notifications, see below for some examples. -e cloudflareddns = \"pover://user@token\" -e cloudflareddns = \"pover://user@token;discord://webhook_id/webhook_token\"","title":"hotio/cloudflareddns"},{"location":"containers/cloudflareddns/#starting-the-container","text":"cli docker run --rm \\ --name cloudflareddns \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e INTERVAL = 300 \\ -e DETECTION_MODE = \"dig-whoami.cloudflare\" \\ -e LOG_LEVEL = 3 \\ -e cloudflareddns = \"\" \\ -e CF_USER = \"your.cf.email@example.com\" \\ -e CF_APIKEY = \"your.global.apikey\" \\ -e CF_APITOKEN = \"\" \\ -e CF_APITOKEN_ZONE = \"\" \\ -e CF_HOSTS = \"test.example.com;test.foobar.com;test2.foobar.com\" \\ -e CF_ZONES = \"example.com;foobar.com;foobar.com\" \\ -e CF_RECORDTYPES = \"A;A;AAAA\" \\ -v /<host_folder_config>:/config \\ hotio/cloudflareddns compose version : \"3.7\" services : cloudflareddns : container_name : cloudflareddns image : hotio/cloudflareddns environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - INTERVAL=300 - DETECTION_MODE=dig-whoami.cloudflare - LOG_LEVEL=3 - cloudflareddns - CF_USER=your.cf.email@example.com - CF_APIKEY=your.global.apikey - CF_APITOKEN - CF_APITOKEN_ZONE - CF_HOSTS=test.example.com;test.foobar.com;test2.foobar.com - CF_ZONES=example.com;foobar.com;foobar.com - CF_RECORDTYPES=A;A;AAAA volumes : - /<host_folder_config>:/config Possible values for DETECTION_MODE are dig-google.com , dig-opendns.com , dig-whoami.cloudflare , curl-icanhazip.com , curl-wtfismyip.com , curl-showmyip.ca , curl-da.gd , curl-seeip.org and curl-ifconfig.co . If you want to get the local ip from a network interface, use something like local:eth0 as DETECTION_MODE . Notice that we give 3 values each time for CF_HOSTS , CF_ZONES and CF_RECORDTYPES . In our example, the domain test.foobar.com belonging to the zone foobar.com will have its A record updated with an ipv4 ip. If you use CF_APITOKEN , you can leave CF_USER and CF_APIKEY empty. IMPORTANT: All the domain names in CF_HOSTS should have properly configured DNS records on Cloudflare, they will not be created.","title":"Starting the container"},{"location":"containers/cloudflareddns/#tags","text":"Tag Description Build release (latest) The main branch","title":"Tags"},{"location":"containers/cloudflareddns/#zone-id","text":"Instead of the zone_name , you can also fill in a zone_id in CF_ZONES . When using a zone_id , you can use a scoped token ( CF_APITOKEN ) that only needs the Zone - DNS - Edit permissions. This improves security. The configuration could look like the example below. -e CF_APITOKEN = \"azkqvJ86wEScojvSJC8DyY67TwqNwZCtomEVrHwt\" -e CF_HOSTS = \"example.com;test.foobar.com\" -e CF_ZONES = \"zbpsi9ceikrdnnym27s2xnp6s5dvj6ep;dccbe6grakumohwwd4amh4o46yupepn8\" -e CF_RECORDTYPES = \"A;A\"","title":"Zone ID"},{"location":"containers/cloudflareddns/#seperate-api-tokens","text":"If you do not prefer to use a zone_id , but prefer some more security, you can use 2 seperate tokens. CF_APITOKEN configured with: Permissions Zone - DNS - Edit Zone Resources Include - Specific zone - example.com Include - Specific zone - foobar.com CF_APITOKEN_ZONE configured with: Permissions Zone - Zone - Read Zone Resources Include - All zones Leaving CF_APITOKEN_ZONE blank would mean that only CF_APITOKEN will be used and thus that token should have all required permissions. Which usually means that the token could edit all zones or not be able to fetch the zone_id from the zone_name .","title":"Seperate API Tokens"},{"location":"containers/cloudflareddns/#configuration-combination-examples","text":"Below are some example configuration combinations, ordered from most secure to least secure. We use a zone_id so that our token only needs the permissions Zone - DNS - Edit . -e CF_APITOKEN = \"azkqvJ86wEScojvSJC8DyY67TwqNwZCtomEVrHwt\" -e CF_HOSTS = \"vpn.example.com;test.foobar.com\" -e CF_ZONES = \"zbpsi9ceikrdnnym27s2xnp6s5dvj6ep;axozor886pyja7nmbcvu5kh7dp9557j4\" -e CF_RECORDTYPES = \"A;A\" We use additionally a CF_APITOKEN_ZONE with the permissions Zone - Zone - Read to query the zones and getting the zone_id . -e CF_APITOKEN = \"azkqvJ86wEScojvSJC8DyY67TwqNwZCtomEVrHwt\" -e CF_APITOKEN_ZONE = \"8m4TxzWb9QHXEpTwQDMugkKuHRavsxoK8qmJ4P7M\" -e CF_HOSTS = \"vpn.example.com;test.foobar.com\" -e CF_ZONES = \"example.com;axozor886pyja7nmbcvu5kh7dp9557j4\" -e CF_RECORDTYPES = \"A;A\" We use only CF_APITOKEN , but with the permissions Zone - DNS - Edit and Zone - Zone - Read . -e CF_APITOKEN = \"azkqvJ86wEScojvSJC8DyY67TwqNwZCtomEVrHwt\" -e CF_HOSTS = \"vpn.example.com;test.foobar.com\" -e CF_ZONES = \"example.com;axozor886pyja7nmbcvu5kh7dp9557j4\" -e CF_RECORDTYPES = \"A;A\" We use CF_USER and CF_APIKEY , basically giving full control over our account. -e CF_USER = \"your.cf.email@example.com\" -e CF_APIKEY = \"your.global.apikey\" -e CF_HOSTS = \"vpn.example.com;test.foobar.com\" -e CF_ZONES = \"example.com;axozor886pyja7nmbcvu5kh7dp9557j4\" -e CF_RECORDTYPES = \"A;A\"","title":"Configuration combination examples"},{"location":"containers/cloudflareddns/#example-of-the-log-output","text":"2020-05-17 17:20:54 - INFO - IPv4 detected by [dig-whoami.cloudflare] is [1.1.1.1]. 2020-05-17 17:20:54 - INFO - [1/1] [A] [vpn.example.com] Reading zone list from Cloudflare. 2020-05-17 17:20:54 - INFO - [1/1] [A] [vpn.example.com] Retrieved zone list from Cloudflare. 2020-05-17 17:20:54 - INFO - [1/1] [A] [vpn.example.com] Zone ID [xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx] found for zone [example.com]. 2020-05-17 17:20:54 - INFO - [1/1] [A] [vpn.example.com] Reading DNS record from Cloudflare. 2020-05-17 17:20:55 - INFO - [1/1] [A] [vpn.example.com] Writing DNS record to cache file [/config/cf-ddns-A-vpn.example.com.cache]. 2020-05-17 17:20:55 - INFO - [1/1] [A] [vpn.example.com] Checking if update is needed. 2020-05-17 17:20:55 - INFO - [1/1] [A] [vpn.example.com] No update needed. 2020-05-17 17:20:55 - INFO - Going to sleep for [300] seconds...","title":"Example of the log output"},{"location":"containers/cloudflareddns/#log-levels","text":"For LOG_LEVEL you can pick 0 , 1 , 2 or 3 . 0 will give no log output. It's not recommended to use. 1 will give you the following output types. It's the recommended value when all things are configured and running as expected. UPDATE, WARNING, ERROR 2 will give you the following output types. Use this if you always wanna see what's going on, but 3 gives you too much output. UPDATE, WARNING, ERROR, INFO 3 will give you the following output types. This is the default. UPDATE, WARNING, ERROR, INFO, DEBUG","title":"Log levels"},{"location":"containers/cloudflareddns/#json-log","text":"Every IP update is also logged to /config/cf-ddns-updates.json . This can be used with the Telegraf JSON parser and the tail input, to get your domain updates into InfluxDB. Example output below. { \"domain\" : \"vpn.example.com\" , \"recordtype\" : \"A\" , \"ip\" : \"1.1.1.1\" , \"timestamp\" : \"2020-05-17T20:27:14Z\" } { \"domain\" : \"vpn.example.com\" , \"recordtype\" : \"A\" , \"ip\" : \"1.1.1.1\" , \"timestamp\" : \"2020-05-17T20:29:26Z\" }","title":"JSON log"},{"location":"containers/cloudflareddns/#cached-results-from-cloudflare","text":"The returned results from Cloudflare are cached. This means minimal api calls to Cloudflare. If you have made any manual changes to the IP on the Cloudflare webinterface, for instance when wanting to test an update, a container restart is needed to clear the cache. The proxy setting (orange cloud) and TTL is also cached and re-set based on the previous value, so if you made any modifications to these settings, you should restart the container so that the script is aware of the new settings.","title":"Cached results from Cloudflare"},{"location":"containers/cloudflareddns/#sending-notifications-using-cloudflareddns","text":"You can send notifications when a DNS record gets updated with a new IP using cloudflareddns . Use the environment variable cloudflareddns to configure notifications, see below for some examples. -e cloudflareddns = \"pover://user@token\" -e cloudflareddns = \"pover://user@token;discord://webhook_id/webhook_token\"","title":"Sending notifications using cloudflareddns"},{"location":"containers/conreq/","text":"GitHub GitHub Registry Docker Hub Conreq Starting the container \u00b6 cli docker run --rm \\ --name conreq \\ -p 8000 :8000 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/conreq compose version : \"3.7\" services : conreq : container_name : conreq image : hotio/conreq ports : - \"8000:8000\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config Tags \u00b6 Tag Description Version Build release (latest) main branch nightly develop branch","title":"hotio/conreq"},{"location":"containers/conreq/#starting-the-container","text":"cli docker run --rm \\ --name conreq \\ -p 8000 :8000 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/conreq compose version : \"3.7\" services : conreq : container_name : conreq image : hotio/conreq ports : - \"8000:8000\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config","title":"Starting the container"},{"location":"containers/conreq/#tags","text":"Tag Description Version Build release (latest) main branch nightly develop branch","title":"Tags"},{"location":"containers/crop/","text":"GitHub GitHub Registry Docker Hub Crop Starting the container \u00b6 cli docker run --rm hotio/crop ... The default ENTRYPOINT is crop . Tags \u00b6 Tag Description Version Build release (latest) GitHub releases nightly Every commit to develop branch","title":"hotio/crop"},{"location":"containers/crop/#starting-the-container","text":"cli docker run --rm hotio/crop ... The default ENTRYPOINT is crop .","title":"Starting the container"},{"location":"containers/crop/#tags","text":"Tag Description Version Build release (latest) GitHub releases nightly Every commit to develop branch","title":"Tags"},{"location":"containers/duplicacy/","text":"GitHub GitHub Registry Docker Hub Duplicacy Starting the container \u00b6 cli docker run --rm \\ --name duplicacy \\ --hostname duplicacy \\ -p 3875 :3875 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ -v /<host_folder_cache>:/cache \\ -v /<host_folder_logs>:/logs \\ hotio/duplicacy compose version : \"3.7\" services : duplicacy : container_name : duplicacy hostname : duplicacy image : hotio/duplicacy ports : - \"3875:3875\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config - /<host_folder_cache>:/cache - /<host_folder_logs>:/logs In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. If you don't want to enter your password every time you restart the container, you can set the environment variable DWE_PASSWORD with your password or starting with version 1.4.1 a file /config/keyring will be created that stores your password encryted if you click the checkmark on the login page. Tags \u00b6 Tag Upstream Version Build release (latest) Stable channel testing Latest channel","title":"hotio/duplicacy"},{"location":"containers/duplicacy/#starting-the-container","text":"cli docker run --rm \\ --name duplicacy \\ --hostname duplicacy \\ -p 3875 :3875 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ -v /<host_folder_cache>:/cache \\ -v /<host_folder_logs>:/logs \\ hotio/duplicacy compose version : \"3.7\" services : duplicacy : container_name : duplicacy hostname : duplicacy image : hotio/duplicacy ports : - \"3875:3875\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config - /<host_folder_cache>:/cache - /<host_folder_logs>:/logs In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. If you don't want to enter your password every time you restart the container, you can set the environment variable DWE_PASSWORD with your password or starting with version 1.4.1 a file /config/keyring will be created that stores your password encryted if you click the checkmark on the login page.","title":"Starting the container"},{"location":"containers/duplicacy/#tags","text":"Tag Upstream Version Build release (latest) Stable channel testing Latest channel","title":"Tags"},{"location":"containers/hdidle/","text":"GitHub GitHub Registry Docker Hub hd-idle Starting the container \u00b6 cli docker run --rm \\ --name hdidle \\ --privileged = true \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e ARGS = \"-d -i 1800\" \\ -v /<host_folder_config>:/config \\ hotio/hdidle compose version : \"3.7\" services : hdidle : container_name : hdidle image : hotio/hdidle privileged : true environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - ARGS=-d -i 1800 volumes : - /<host_folder_config>:/config It's not recommended to use --privileged , it's best to pass through individual devices and only allow the required privileges. We are using --privileged here for ease of use. Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases","title":"hotio/hdidle"},{"location":"containers/hdidle/#starting-the-container","text":"cli docker run --rm \\ --name hdidle \\ --privileged = true \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e ARGS = \"-d -i 1800\" \\ -v /<host_folder_config>:/config \\ hotio/hdidle compose version : \"3.7\" services : hdidle : container_name : hdidle image : hotio/hdidle privileged : true environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - ARGS=-d -i 1800 volumes : - /<host_folder_config>:/config It's not recommended to use --privileged , it's best to pass through individual devices and only allow the required privileges. We are using --privileged here for ease of use.","title":"Starting the container"},{"location":"containers/hdidle/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"Tags"},{"location":"containers/jackett/","text":"GitHub GitHub Registry Docker Hub Jackett Starting the container \u00b6 cli docker run --rm \\ --name jackett \\ -p 9117 :9117 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/jackett compose version : \"3.7\" services : jackett : container_name : jackett image : hotio/jackett ports : - \"9117:9117\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/jackett"},{"location":"containers/jackett/#starting-the-container","text":"cli docker run --rm \\ --name jackett \\ -p 9117 :9117 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/jackett compose version : \"3.7\" services : jackett : container_name : jackett image : hotio/jackett ports : - \"9117:9117\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config","title":"Starting the container"},{"location":"containers/jackett/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"Tags"},{"location":"containers/jellyfin/","text":"GitHub GitHub Registry Docker Hub Jellyfin Starting the container \u00b6 cli docker run --rm \\ --name jellyfin \\ -p 8096 :8096 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/jellyfin compose version : \"3.7\" services : jellyfin : container_name : jellyfin image : hotio/jellyfin ports : - \"8096:8096\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) Releases testing Release Candidates nightly Every commit to master branch Configuration \u00b6 The following jellyfin path locations are used by default. JELLYFIN_CONFIG_DIR = \"/config\" JELLYFIN_DATA_DIR = \"/config/data\" JELLYFIN_LOG_DIR = \"/config/log\" JELLYFIN_CACHE_DIR = \"/config/cache\" You can override these locations by setting them to a different value with a docker environment variable. Hardware support \u00b6 To make your hardware devices available inside the container use the following argument --device=/dev/dri:/dev/dri for Intel QuickSync and --device=/dev/dvb:/dev/dvb for a tuner. NVIDIA users should go visit the NVIDIA github page for instructions. For Raspberry Pi OpenMAX you'll need to use --device=/dev/vchiq:/dev/vchiq -v /opt/vc/lib:/opt/vc/lib , V4L2 will need --device=/dev/video10:/dev/video10 --device=/dev/video11:/dev/video11 --device=/dev/video12:/dev/video12 and MMAL needs --device=/dev/vcsm:/dev/vcsm or --device=/dev/vc-mem:/dev/vc-mem .","title":"hotio/jellyfin"},{"location":"containers/jellyfin/#starting-the-container","text":"cli docker run --rm \\ --name jellyfin \\ -p 8096 :8096 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/jellyfin compose version : \"3.7\" services : jellyfin : container_name : jellyfin image : hotio/jellyfin ports : - \"8096:8096\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/jellyfin/#tags","text":"Tag Upstream Version Build release (latest) Releases testing Release Candidates nightly Every commit to master branch","title":"Tags"},{"location":"containers/jellyfin/#configuration","text":"The following jellyfin path locations are used by default. JELLYFIN_CONFIG_DIR = \"/config\" JELLYFIN_DATA_DIR = \"/config/data\" JELLYFIN_LOG_DIR = \"/config/log\" JELLYFIN_CACHE_DIR = \"/config/cache\" You can override these locations by setting them to a different value with a docker environment variable.","title":"Configuration"},{"location":"containers/jellyfin/#hardware-support","text":"To make your hardware devices available inside the container use the following argument --device=/dev/dri:/dev/dri for Intel QuickSync and --device=/dev/dvb:/dev/dvb for a tuner. NVIDIA users should go visit the NVIDIA github page for instructions. For Raspberry Pi OpenMAX you'll need to use --device=/dev/vchiq:/dev/vchiq -v /opt/vc/lib:/opt/vc/lib , V4L2 will need --device=/dev/video10:/dev/video10 --device=/dev/video11:/dev/video11 --device=/dev/video12:/dev/video12 and MMAL needs --device=/dev/vcsm:/dev/vcsm or --device=/dev/vc-mem:/dev/vc-mem .","title":"Hardware support"},{"location":"containers/lidarr/","text":"GitHub GitHub Registry Docker Hub Lidarr Starting the container \u00b6 cli docker run --rm \\ --name lidarr \\ -p 8686 :8686 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/lidarr compose version : \"3.7\" services : lidarr : container_name : lidarr image : hotio/lidarr ports : - \"8686:8686\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) master testing develop nightly nightly","title":"hotio/lidarr"},{"location":"containers/lidarr/#starting-the-container","text":"cli docker run --rm \\ --name lidarr \\ -p 8686 :8686 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/lidarr compose version : \"3.7\" services : lidarr : container_name : lidarr image : hotio/lidarr ports : - \"8686:8686\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/lidarr/#tags","text":"Tag Upstream Version Build release (latest) master testing develop nightly nightly","title":"Tags"},{"location":"containers/mergerfs/","text":"GitHub GitHub Registry Docker Hub MergerFS Starting the container \u00b6 cli docker run --rm hotio/mergerfs ... The default ENTRYPOINT is mergerfs -f . Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch Using the mergerfs mount on the host \u00b6 By setting the bind-propagation to shared on the volume mountpoint , like this -v /data/mountpoint:/mountpoint:shared , you are able to access the mount from the host. If you want to use this mount in another container, the best solution is to create a volume on the parent folder of that mount with bind-propagation set to slave . For example, -v /data:/data:slave ( /data on the host, would contain the previously created volume mountpoint ). Doing it like this will ensure that when the container creating the mount restarts, the other containers using that mount will recover and keep working. Extra docker privileges \u00b6 In most cases you will need some or all of the following flags added to your command to get the required docker privileges when using a mergerfs mount. --security-opt apparmor:unconfined --cap-add SYS_ADMIN --device /dev/fuse","title":"hotio/mergerfs"},{"location":"containers/mergerfs/#starting-the-container","text":"cli docker run --rm hotio/mergerfs ... The default ENTRYPOINT is mergerfs -f .","title":"Starting the container"},{"location":"containers/mergerfs/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch","title":"Tags"},{"location":"containers/mergerfs/#using-the-mergerfs-mount-on-the-host","text":"By setting the bind-propagation to shared on the volume mountpoint , like this -v /data/mountpoint:/mountpoint:shared , you are able to access the mount from the host. If you want to use this mount in another container, the best solution is to create a volume on the parent folder of that mount with bind-propagation set to slave . For example, -v /data:/data:slave ( /data on the host, would contain the previously created volume mountpoint ). Doing it like this will ensure that when the container creating the mount restarts, the other containers using that mount will recover and keep working.","title":"Using the mergerfs mount on the host"},{"location":"containers/mergerfs/#extra-docker-privileges","text":"In most cases you will need some or all of the following flags added to your command to get the required docker privileges when using a mergerfs mount. --security-opt apparmor:unconfined --cap-add SYS_ADMIN --device /dev/fuse","title":"Extra docker privileges"},{"location":"containers/mono/","text":"GitHub GitHub Registry Docker Hub Tags \u00b6 Tag Description Build bionic Based on Ubuntu 18.04 focal Based on Ubuntu 20.04","title":"hotio/mono"},{"location":"containers/mono/#tags","text":"Tag Description Build bionic Based on Ubuntu 18.04 focal Based on Ubuntu 20.04","title":"Tags"},{"location":"containers/movearr/","text":"GitHub GitHub Registry Docker Hub Movearr Starting the container \u00b6 cli docker run --rm hotio/movearr ... The default ENTRYPOINT is movearr . Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch","title":"hotio/movearr"},{"location":"containers/movearr/#starting-the-container","text":"cli docker run --rm hotio/movearr ... The default ENTRYPOINT is movearr .","title":"Starting the container"},{"location":"containers/movearr/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch","title":"Tags"},{"location":"containers/mylar3/","text":"GitHub GitHub Registry Docker Hub Mylar3 Starting the container \u00b6 cli docker run --rm \\ --name mylar3 \\ -p 8090 :8090 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/mylar3 compose version : \"3.7\" services : mylar3 : container_name : mylar3 image : hotio/mylar3 ports : - \"8090:8090\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to python3-dev branch","title":"hotio/mylar3"},{"location":"containers/mylar3/#starting-the-container","text":"cli docker run --rm \\ --name mylar3 \\ -p 8090 :8090 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/mylar3 compose version : \"3.7\" services : mylar3 : container_name : mylar3 image : hotio/mylar3 ports : - \"8090:8090\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/mylar3/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to python3-dev branch","title":"Tags"},{"location":"containers/nzbget/","text":"GitHub GitHub Registry Docker Hub NZBGet Starting the container \u00b6 cli docker run --rm \\ --name nzbget \\ -p 6789 :6789 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/nzbget compose version : \"3.7\" services : nzbget : container_name : nzbget image : hotio/nzbget ports : - \"6789:6789\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/nzbget"},{"location":"containers/nzbget/#starting-the-container","text":"cli docker run --rm \\ --name nzbget \\ -p 6789 :6789 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/nzbget compose version : \"3.7\" services : nzbget : container_name : nzbget image : hotio/nzbget ports : - \"6789:6789\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/nzbget/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"Tags"},{"location":"containers/nzbhydra2/","text":"GitHub GitHub Registry Docker Hub NZBHydra2 Starting the container \u00b6 cli docker run --rm \\ --name nzbhydra2 \\ -p 5076 :5076 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/nzbhydra2 compose version : \"3.7\" services : nzbhydra2 : container_name : nzbhydra2 image : hotio/nzbhydra2 ports : - \"5076:5076\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/nzbhydra2"},{"location":"containers/nzbhydra2/#starting-the-container","text":"cli docker run --rm \\ --name nzbhydra2 \\ -p 5076 :5076 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/nzbhydra2 compose version : \"3.7\" services : nzbhydra2 : container_name : nzbhydra2 image : hotio/nzbhydra2 ports : - \"5076:5076\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config","title":"Starting the container"},{"location":"containers/nzbhydra2/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"Tags"},{"location":"containers/ombi/","text":"GitHub GitHub Registry Docker Hub Ombi Starting the container \u00b6 cli docker run --rm \\ --name ombi \\ -p 5000 :5000 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/ombi compose version : \"3.7\" services : ombi : container_name : ombi image : hotio/ombi ports : - \"5000:5000\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config Tags \u00b6 Tag Upstream Version Build release (latest) v3 releases testing v4 releases","title":"hotio/ombi"},{"location":"containers/ombi/#starting-the-container","text":"cli docker run --rm \\ --name ombi \\ -p 5000 :5000 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/ombi compose version : \"3.7\" services : ombi : container_name : ombi image : hotio/ombi ports : - \"5000:5000\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config","title":"Starting the container"},{"location":"containers/ombi/#tags","text":"Tag Upstream Version Build release (latest) v3 releases testing v4 releases","title":"Tags"},{"location":"containers/overseerr/","text":"GitHub GitHub Registry Docker Hub Overseerr Starting the container \u00b6 cli docker run --rm \\ --name overseerr \\ -p 5055 :5055 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/overseerr compose version : \"3.7\" services : overseerr : container_name : overseerr image : hotio/overseerr ports : - \"5055:5055\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to develop branch Using a secure Plex connection \u00b6 If you want to keep using secure connections within Plex, but don't want to buy your own domain and keep the connection between Overseerr and Plex inside of their Docker network. Follow the below procedure. We'll use Google Chrome in this example. Visit https://app.plex.tv and make sure you are logged in. Open Chrome DevTools (usually F12) and open the Console tab, then refresh your browser window. One of the very first lines you will see is [Servers] Initialize server with token, ... , in that message you should see some url that looks like https://10-1-0-100.xxxxxxxxxxxxx.plex.direct:32400 . Part of that url can be used in your Overseerr settings, the part 10-1-0-100.xxxxxxxxxxxxx.plex.direct is what you'll need to copy/paste, the port is in a seperate input box and enable SSL. You should however give the Plex container a static IP if you don't wanna do this every 5 minutes.","title":"hotio/overseerr"},{"location":"containers/overseerr/#starting-the-container","text":"cli docker run --rm \\ --name overseerr \\ -p 5055 :5055 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/overseerr compose version : \"3.7\" services : overseerr : container_name : overseerr image : hotio/overseerr ports : - \"5055:5055\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config","title":"Starting the container"},{"location":"containers/overseerr/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to develop branch","title":"Tags"},{"location":"containers/overseerr/#using-a-secure-plex-connection","text":"If you want to keep using secure connections within Plex, but don't want to buy your own domain and keep the connection between Overseerr and Plex inside of their Docker network. Follow the below procedure. We'll use Google Chrome in this example. Visit https://app.plex.tv and make sure you are logged in. Open Chrome DevTools (usually F12) and open the Console tab, then refresh your browser window. One of the very first lines you will see is [Servers] Initialize server with token, ... , in that message you should see some url that looks like https://10-1-0-100.xxxxxxxxxxxxx.plex.direct:32400 . Part of that url can be used in your Overseerr settings, the part 10-1-0-100.xxxxxxxxxxxxx.plex.direct is what you'll need to copy/paste, the port is in a seperate input box and enable SSL. You should however give the Plex container a static IP if you don't wanna do this every 5 minutes.","title":"Using a secure Plex connection"},{"location":"containers/plex/","text":"GitHub GitHub Registry Docker Hub Plex Starting the container \u00b6 cli docker run --rm \\ --name plex \\ -p 32400 :32400 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e PLEX_CLAIM = \"\" \\ -e ADVERTISE_IP = \"\" \\ -e ALLOWED_NETWORKS = \"\" \\ -e PLEX_PASS = \"no\" \\ -v /<host_folder_config>:/config \\ -v /<host_folder_transcode>:/transcode \\ hotio/plex compose version : \"3.7\" services : plex : container_name : plex image : hotio/plex ports : - \"32400:32400\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - PLEX_CLAIM - ADVERTISE_IP - ALLOWED_NETWORKS - PLEX_PASS=no volumes : - /<host_folder_config>:/config - /<host_folder_transcode>:/transcode In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) Releases Volumes \u00b6 By default the container has 2 volumes defined, the volume /config that contains the configuration files and the volume /transcode which is used as the default transcode directory. Claim your server \u00b6 Go to plex.tv/claim and login with your account, copy the claim code and add it to the environment variable like this -e PLEX_CLAIM=\"claim-xxxxxxxxxxxxxxxxxxxx\" . When starting the new plex server for the first time, the server will be added to your account. Plex Pass \u00b6 If you are a Plex Pass subscriber, you can enable the install of beta builds with -e PLEX_PASS=\"yes\" . When the container starts, a version check is done for the latest beta and installed if a newer version is found. Environment variables ADVERTISE_IP and ALLOWED_NETWORKS \u00b6 The variables correspond to the below plex network settings. TOP secret stuff \u00b6 If you do -e PLEX_PASS=\"https://...\" , stuff happens for which no support will be given. Hardware support \u00b6 To make your hardware devices available inside the container use the following argument --device=/dev/dri:/dev/dri for Intel QuickSync and --device=/dev/dvb:/dev/dvb for a tuner. NVIDIA users should go visit the NVIDIA github page for instructions.","title":"hotio/plex"},{"location":"containers/plex/#starting-the-container","text":"cli docker run --rm \\ --name plex \\ -p 32400 :32400 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e PLEX_CLAIM = \"\" \\ -e ADVERTISE_IP = \"\" \\ -e ALLOWED_NETWORKS = \"\" \\ -e PLEX_PASS = \"no\" \\ -v /<host_folder_config>:/config \\ -v /<host_folder_transcode>:/transcode \\ hotio/plex compose version : \"3.7\" services : plex : container_name : plex image : hotio/plex ports : - \"32400:32400\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - PLEX_CLAIM - ADVERTISE_IP - ALLOWED_NETWORKS - PLEX_PASS=no volumes : - /<host_folder_config>:/config - /<host_folder_transcode>:/transcode In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/plex/#tags","text":"Tag Upstream Version Build release (latest) Releases","title":"Tags"},{"location":"containers/plex/#volumes","text":"By default the container has 2 volumes defined, the volume /config that contains the configuration files and the volume /transcode which is used as the default transcode directory.","title":"Volumes"},{"location":"containers/plex/#claim-your-server","text":"Go to plex.tv/claim and login with your account, copy the claim code and add it to the environment variable like this -e PLEX_CLAIM=\"claim-xxxxxxxxxxxxxxxxxxxx\" . When starting the new plex server for the first time, the server will be added to your account.","title":"Claim your server"},{"location":"containers/plex/#plex-pass","text":"If you are a Plex Pass subscriber, you can enable the install of beta builds with -e PLEX_PASS=\"yes\" . When the container starts, a version check is done for the latest beta and installed if a newer version is found.","title":"Plex Pass"},{"location":"containers/plex/#environment-variables-advertise_ip-and-allowed_networks","text":"The variables correspond to the below plex network settings.","title":"Environment variables ADVERTISE_IP and ALLOWED_NETWORKS"},{"location":"containers/plex/#top-secret-stuff","text":"If you do -e PLEX_PASS=\"https://...\" , stuff happens for which no support will be given.","title":"TOP secret stuff"},{"location":"containers/plex/#hardware-support","text":"To make your hardware devices available inside the container use the following argument --device=/dev/dri:/dev/dri for Intel QuickSync and --device=/dev/dvb:/dev/dvb for a tuner. NVIDIA users should go visit the NVIDIA github page for instructions.","title":"Hardware support"},{"location":"containers/plexarr/","text":"GitHub GitHub Registry Docker Hub Plexarr Starting the container \u00b6 cli docker run --rm hotio/plexarr ... The default ENTRYPOINT is plexarr . Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch Getting a Plex token for use in your configuration \u00b6 Run the following command, but replace <plex_username> and <plex_password> with your actual username and password. docker run --rm --entrypoint get-token hotio/plexarr <plex_username> <plex_password> You should see something like this, if all went well: Trying to get a Plex token... Your Plex token is: xxxxxxxxxxxxxxxxxxxx","title":"hotio/plexarr"},{"location":"containers/plexarr/#starting-the-container","text":"cli docker run --rm hotio/plexarr ... The default ENTRYPOINT is plexarr .","title":"Starting the container"},{"location":"containers/plexarr/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch","title":"Tags"},{"location":"containers/plexarr/#getting-a-plex-token-for-use-in-your-configuration","text":"Run the following command, but replace <plex_username> and <plex_password> with your actual username and password. docker run --rm --entrypoint get-token hotio/plexarr <plex_username> <plex_password> You should see something like this, if all went well: Trying to get a Plex token... Your Plex token is: xxxxxxxxxxxxxxxxxxxx","title":"Getting a Plex token for use in your configuration"},{"location":"containers/qbittorrent/","text":"GitHub GitHub Registry Docker Hub qBittorrent Starting the container \u00b6 cli docker run --rm \\ --name qbittorrent \\ -p 8080 :8080 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/qbittorrent compose version : \"3.7\" services : qbittorrent : container_name : qbittorrent image : hotio/qbittorrent ports : - \"8080:8080\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) Stable testing Unstable WireGuard VPN support \u00b6 This is probably not going to work if your OS has no kernel with WireGuard support. Tested Operating Systems: Ubuntu 18.04 Ubuntu 20.04 Unraid 6.8.3 Unraid 6.9 RC2 macOS Big Sur 11.2.1 Apple M1 cli docker run --rm \\ --name qbittorrent \\ -p 8080 :8080 \\ -p 8118 :8118 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e VPN_ENABLED = \"true\" \\ -e VPN_LAN_NETWORK = \"\" \\ -e VPN_CONF = \"wg0\" \\ -e VPN_ADDITIONAL_PORTS = \"\" \\ -e PRIVOXY_ENABLED = \"false\" \\ -v /<host_folder_config>:/config \\ --cap-add = NET_ADMIN \\ --sysctl = \"net.ipv4.conf.all.src_valid_mark=1\" \\ --sysctl = \"net.ipv6.conf.all.disable_ipv6=0\" \\ hotio/qbittorrent compose version : \"3.7\" services : qbittorrent : container_name : qbittorrent image : hotio/qbittorrent ports : - \"8080:8080\" - \"8118:8118\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - VPN_ENABLED=true - VPN_LAN_NETWORK - VPN_CONF=wg0 - VPN_ADDITIONAL_PORTS - PRIVOXY_ENABLED=false volumes : - /<host_folder_config>:/config cap_add : - NET_ADMIN sysctls : - net.ipv4.conf.all.src_valid_mark=1 - net.ipv6.conf.all.disable_ipv6=0 There needs to be a file wg0.conf located in /config/wireguard and you need to set the variable VPN_ENABLED to true for the VPN to start. The part with net.ipv6.conf.all.disable_ipv6=0 can be removed or set to 1 if there is no need for ipv6, no attempt will be made in that case to set ip6tables rules and can prevent an error if the module ip6table_filter isn't loaded on the host. The WireGuard configuration should not have any ipv6 related stuff when ipv6 is disabled, otherwise creating the interface will fail. If your vpn provider supports ipv6 and you keep it enabled, you'll have full ipv6 connectivity over the vpn connection (confirmed with Mullvad). If for any reason there's a failure trying to setup ip6tables rules, you'll probably need to do sudo modprobe ip6table_filter on the host, this will mostly happen on systems that have ipv6 completely disabled. The environment variable VPN_LAN_NETWORK can be set to for example 192.168.1.0/24 , 192.168.1.0/24,192.168.44.0/24 or 192.168.1.33 , so you can get access to the qBittorrent webui. If you need to expose additional ports you can use VPN_ADDITIONAL_PORTS , for example VPN_ADDITIONAL_PORTS=7878/tcp,9117/tcp . Every port in this list will be blocked on the vpn interface, so that there's no risk that they might be exposed to the world via the vpn (mostly there in case your vpn provider screws up and piece of mind). Why would you need this? Wanting to route traffic from other containers over the vpn is probably the most used scenario. wg0.conf example \u00b6 This is an example of how your wg0.conf could look like. [Interface] PrivateKey = supersecretprivatekey Address = xx.xx.xxx.xxx/32 DNS = 1.1.1.1 [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xxx.x.xxx.x:51820 TorGuard instructions \u00b6 While Mullvad is pretty straightforward to setup by using the wg0.conf example from above, TorGuard is a bit more complex. Our wg0.conf should look something like this: # TorGuard WireGuard Config [Interface] PrivateKey = secretprivatekey ListenPort = 51820 DNS = 1.1.1.1 Address = xx.xx.xxx.xx/24 PreUp = bash /config/wireguard/torguard.sh [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xx.xxx.xx.xxx:1443 PersistentKeepalive = 25 Pay attention to PreUp = bash /config/wireguard/torguard.sh in our config. That command will execute the below script that you should create in /config/wireguard/torguard.sh , this script will get executed just before starting WireGuard. 1 2 3 4 5 6 7 #!/usr/bin/bash pubkey = $( grep PrivateKey \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' | wg pubkey ) wgserver = $( grep Endpoint \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' ) curl -ksG -u \" ${ TORGUARD_USER } \" : \" ${ TORGUARD_PASS } \" \\ --data-urlencode \"public-key= ${ pubkey } \" \"https:// ${ wgserver } /api/v1/setup\" You will also have to add the additional environment variables TORGUARD_USER and TORGUARD_PASS or fill them in into the script directly (see curl command). These credentials can be found here . My experience with getting TorGuard working wasn't the smoothest journey to say the least. I had to click around quite a bit and finally after generating my 3rd config it worked. On the Netherlands server for example I didn't get any internet connectivity and at first I was unable to get port forwarding working on the Germany server. All of a sudden after generating the 3rd config and also pasting in the ip found under My Fixed IPs , that seems to populate when doing a Port Forward Request, I managed to get port forwarding working. So don't give up too soon, it can all work eventually. VueTorrent \u00b6 This image comes bundled with the alternative Web UI VueTorrent, to enable it you'll have to adjust your settings like pictured below.","title":"hotio/qbittorrent"},{"location":"containers/qbittorrent/#starting-the-container","text":"cli docker run --rm \\ --name qbittorrent \\ -p 8080 :8080 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/qbittorrent compose version : \"3.7\" services : qbittorrent : container_name : qbittorrent image : hotio/qbittorrent ports : - \"8080:8080\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/qbittorrent/#tags","text":"Tag Upstream Version Build release (latest) Stable testing Unstable","title":"Tags"},{"location":"containers/qbittorrent/#wireguard-vpn-support","text":"This is probably not going to work if your OS has no kernel with WireGuard support. Tested Operating Systems: Ubuntu 18.04 Ubuntu 20.04 Unraid 6.8.3 Unraid 6.9 RC2 macOS Big Sur 11.2.1 Apple M1 cli docker run --rm \\ --name qbittorrent \\ -p 8080 :8080 \\ -p 8118 :8118 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e VPN_ENABLED = \"true\" \\ -e VPN_LAN_NETWORK = \"\" \\ -e VPN_CONF = \"wg0\" \\ -e VPN_ADDITIONAL_PORTS = \"\" \\ -e PRIVOXY_ENABLED = \"false\" \\ -v /<host_folder_config>:/config \\ --cap-add = NET_ADMIN \\ --sysctl = \"net.ipv4.conf.all.src_valid_mark=1\" \\ --sysctl = \"net.ipv6.conf.all.disable_ipv6=0\" \\ hotio/qbittorrent compose version : \"3.7\" services : qbittorrent : container_name : qbittorrent image : hotio/qbittorrent ports : - \"8080:8080\" - \"8118:8118\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - VPN_ENABLED=true - VPN_LAN_NETWORK - VPN_CONF=wg0 - VPN_ADDITIONAL_PORTS - PRIVOXY_ENABLED=false volumes : - /<host_folder_config>:/config cap_add : - NET_ADMIN sysctls : - net.ipv4.conf.all.src_valid_mark=1 - net.ipv6.conf.all.disable_ipv6=0 There needs to be a file wg0.conf located in /config/wireguard and you need to set the variable VPN_ENABLED to true for the VPN to start. The part with net.ipv6.conf.all.disable_ipv6=0 can be removed or set to 1 if there is no need for ipv6, no attempt will be made in that case to set ip6tables rules and can prevent an error if the module ip6table_filter isn't loaded on the host. The WireGuard configuration should not have any ipv6 related stuff when ipv6 is disabled, otherwise creating the interface will fail. If your vpn provider supports ipv6 and you keep it enabled, you'll have full ipv6 connectivity over the vpn connection (confirmed with Mullvad). If for any reason there's a failure trying to setup ip6tables rules, you'll probably need to do sudo modprobe ip6table_filter on the host, this will mostly happen on systems that have ipv6 completely disabled. The environment variable VPN_LAN_NETWORK can be set to for example 192.168.1.0/24 , 192.168.1.0/24,192.168.44.0/24 or 192.168.1.33 , so you can get access to the qBittorrent webui. If you need to expose additional ports you can use VPN_ADDITIONAL_PORTS , for example VPN_ADDITIONAL_PORTS=7878/tcp,9117/tcp . Every port in this list will be blocked on the vpn interface, so that there's no risk that they might be exposed to the world via the vpn (mostly there in case your vpn provider screws up and piece of mind). Why would you need this? Wanting to route traffic from other containers over the vpn is probably the most used scenario.","title":"WireGuard VPN support"},{"location":"containers/qbittorrent/#wg0conf-example","text":"This is an example of how your wg0.conf could look like. [Interface] PrivateKey = supersecretprivatekey Address = xx.xx.xxx.xxx/32 DNS = 1.1.1.1 [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xxx.x.xxx.x:51820","title":"wg0.conf example"},{"location":"containers/qbittorrent/#torguard-instructions","text":"While Mullvad is pretty straightforward to setup by using the wg0.conf example from above, TorGuard is a bit more complex. Our wg0.conf should look something like this: # TorGuard WireGuard Config [Interface] PrivateKey = secretprivatekey ListenPort = 51820 DNS = 1.1.1.1 Address = xx.xx.xxx.xx/24 PreUp = bash /config/wireguard/torguard.sh [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xx.xxx.xx.xxx:1443 PersistentKeepalive = 25 Pay attention to PreUp = bash /config/wireguard/torguard.sh in our config. That command will execute the below script that you should create in /config/wireguard/torguard.sh , this script will get executed just before starting WireGuard. 1 2 3 4 5 6 7 #!/usr/bin/bash pubkey = $( grep PrivateKey \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' | wg pubkey ) wgserver = $( grep Endpoint \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' ) curl -ksG -u \" ${ TORGUARD_USER } \" : \" ${ TORGUARD_PASS } \" \\ --data-urlencode \"public-key= ${ pubkey } \" \"https:// ${ wgserver } /api/v1/setup\" You will also have to add the additional environment variables TORGUARD_USER and TORGUARD_PASS or fill them in into the script directly (see curl command). These credentials can be found here . My experience with getting TorGuard working wasn't the smoothest journey to say the least. I had to click around quite a bit and finally after generating my 3rd config it worked. On the Netherlands server for example I didn't get any internet connectivity and at first I was unable to get port forwarding working on the Germany server. All of a sudden after generating the 3rd config and also pasting in the ip found under My Fixed IPs , that seems to populate when doing a Port Forward Request, I managed to get port forwarding working. So don't give up too soon, it can all work eventually.","title":"TorGuard instructions"},{"location":"containers/qbittorrent/#vuetorrent","text":"This image comes bundled with the alternative Web UI VueTorrent, to enable it you'll have to adjust your settings like pictured below.","title":"VueTorrent"},{"location":"containers/qflood/","text":"GitHub GitHub Registry Docker Hub qBittorrent Flood What is this? A docker image with qBittorrent and the Flood UI, also optional WireGuard VPN support. Starting the container \u00b6 cli docker run --rm \\ --name qflood \\ -p 8080 :8080 \\ -p 3000 :3000 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e FLOOD_AUTH = \"false\" \\ -v /<host_folder_config>:/config \\ hotio/qflood compose version : \"3.7\" services : qflood : container_name : qflood image : hotio/qflood ports : - \"8080:8080\" - \"3000:3000\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - FLOOD_AUTH=false volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) Releases WireGuard VPN support \u00b6 This is probably not going to work if your OS has no kernel with WireGuard support. Tested Operating Systems: Ubuntu 18.04 Ubuntu 20.04 Unraid 6.8.3 Unraid 6.9 RC2 macOS Big Sur 11.2.1 Apple M1 cli docker run --rm \\ --name qflood \\ -p 8080 :8080 \\ -p 3000 :3000 \\ -p 8118 :8118 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e VPN_ENABLED = \"true\" \\ -e VPN_LAN_NETWORK = \"\" \\ -e VPN_CONF = \"wg0\" \\ -e VPN_ADDITIONAL_PORTS = \"\" \\ -e PRIVOXY_ENABLED = \"false\" \\ -e FLOOD_AUTH = \"false\" \\ -v /<host_folder_config>:/config \\ --cap-add = NET_ADMIN \\ --sysctl = \"net.ipv4.conf.all.src_valid_mark=1\" \\ --sysctl = \"net.ipv6.conf.all.disable_ipv6=0\" \\ hotio/qflood compose version : \"3.7\" services : qflood : container_name : qflood image : hotio/qflood ports : - \"8080:8080\" - \"3000:3000\" - \"8118:8118\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - VPN_ENABLED=true - VPN_LAN_NETWORK - VPN_CONF=wg0 - VPN_ADDITIONAL_PORTS - PRIVOXY_ENABLED=false - FLOOD_AUTH=false volumes : - /<host_folder_config>:/config cap_add : - NET_ADMIN sysctls : - net.ipv4.conf.all.src_valid_mark=1 - net.ipv6.conf.all.disable_ipv6=0 There needs to be a file wg0.conf located in /config/wireguard and you need to set the variable VPN_ENABLED to true for the VPN to start. The part with net.ipv6.conf.all.disable_ipv6=0 can be removed or set to 1 if there is no need for ipv6, no attempt will be made in that case to set ip6tables rules and can prevent an error if the module ip6table_filter isn't loaded on the host. The WireGuard configuration should not have any ipv6 related stuff when ipv6 is disabled, otherwise creating the interface will fail. If your vpn provider supports ipv6 and you keep it enabled, you'll have full ipv6 connectivity over the vpn connection (confirmed with Mullvad). If for any reason there's a failure trying to setup ip6tables rules, you'll probably need to do sudo modprobe ip6table_filter on the host, this will mostly happen on systems that have ipv6 completely disabled. The environment variable VPN_LAN_NETWORK can be set to for example 192.168.1.0/24 , 192.168.1.0/24,192.168.44.0/24 or 192.168.1.33 , so you can get access to the qBittorrent webui. If you need to expose additional ports you can use VPN_ADDITIONAL_PORTS , for example VPN_ADDITIONAL_PORTS=7878/tcp,9117/tcp . Every port in this list will be blocked on the vpn interface, so that there's no risk that they might be exposed to the world via the vpn (mostly there in case your vpn provider screws up and piece of mind). Why would you need this? Wanting to route traffic from other containers over the vpn is probably the most used scenario. wg0.conf example \u00b6 This is an example of how your wg0.conf could look like. [Interface] PrivateKey = supersecretprivatekey Address = xx.xx.xxx.xxx/32 DNS = 1.1.1.1 [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xxx.x.xxx.x:51820 TorGuard instructions \u00b6 While Mullvad is pretty straightforward to setup by using the wg0.conf example from above, TorGuard is a bit more complex. Our wg0.conf should look something like this: # TorGuard WireGuard Config [Interface] PrivateKey = secretprivatekey ListenPort = 51820 DNS = 1.1.1.1 Address = xx.xx.xxx.xx/24 PreUp = bash /config/wireguard/torguard.sh [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xx.xxx.xx.xxx:1443 PersistentKeepalive = 25 Pay attention to PreUp = bash /config/wireguard/torguard.sh in our config. That command will execute the below script that you should create in /config/wireguard/torguard.sh , this script will get executed just before starting WireGuard. 1 2 3 4 5 6 7 #!/usr/bin/bash pubkey = $( grep PrivateKey \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' | wg pubkey ) wgserver = $( grep Endpoint \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' ) curl -ksG -u \" ${ TORGUARD_USER } \" : \" ${ TORGUARD_PASS } \" \\ --data-urlencode \"public-key= ${ pubkey } \" \"https:// ${ wgserver } /api/v1/setup\" You will also have to add the additional environment variables TORGUARD_USER and TORGUARD_PASS or fill them in into the script directly (see curl command). These credentials can be found here . My experience with getting TorGuard working wasn't the smoothest journey to say the least. I had to click around quite a bit and finally after generating my 3rd config it worked. On the Netherlands server for example I didn't get any internet connectivity and at first I was unable to get port forwarding working on the Germany server. All of a sudden after generating the 3rd config and also pasting in the ip found under My Fixed IPs , that seems to populate when doing a Port Forward Request, I managed to get port forwarding working. So don't give up too soon, it can all work eventually.","title":"hotio/qflood"},{"location":"containers/qflood/#starting-the-container","text":"cli docker run --rm \\ --name qflood \\ -p 8080 :8080 \\ -p 3000 :3000 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e FLOOD_AUTH = \"false\" \\ -v /<host_folder_config>:/config \\ hotio/qflood compose version : \"3.7\" services : qflood : container_name : qflood image : hotio/qflood ports : - \"8080:8080\" - \"3000:3000\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - FLOOD_AUTH=false volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/qflood/#tags","text":"Tag Upstream Version Build release (latest) Releases","title":"Tags"},{"location":"containers/qflood/#wireguard-vpn-support","text":"This is probably not going to work if your OS has no kernel with WireGuard support. Tested Operating Systems: Ubuntu 18.04 Ubuntu 20.04 Unraid 6.8.3 Unraid 6.9 RC2 macOS Big Sur 11.2.1 Apple M1 cli docker run --rm \\ --name qflood \\ -p 8080 :8080 \\ -p 3000 :3000 \\ -p 8118 :8118 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e VPN_ENABLED = \"true\" \\ -e VPN_LAN_NETWORK = \"\" \\ -e VPN_CONF = \"wg0\" \\ -e VPN_ADDITIONAL_PORTS = \"\" \\ -e PRIVOXY_ENABLED = \"false\" \\ -e FLOOD_AUTH = \"false\" \\ -v /<host_folder_config>:/config \\ --cap-add = NET_ADMIN \\ --sysctl = \"net.ipv4.conf.all.src_valid_mark=1\" \\ --sysctl = \"net.ipv6.conf.all.disable_ipv6=0\" \\ hotio/qflood compose version : \"3.7\" services : qflood : container_name : qflood image : hotio/qflood ports : - \"8080:8080\" - \"3000:3000\" - \"8118:8118\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - VPN_ENABLED=true - VPN_LAN_NETWORK - VPN_CONF=wg0 - VPN_ADDITIONAL_PORTS - PRIVOXY_ENABLED=false - FLOOD_AUTH=false volumes : - /<host_folder_config>:/config cap_add : - NET_ADMIN sysctls : - net.ipv4.conf.all.src_valid_mark=1 - net.ipv6.conf.all.disable_ipv6=0 There needs to be a file wg0.conf located in /config/wireguard and you need to set the variable VPN_ENABLED to true for the VPN to start. The part with net.ipv6.conf.all.disable_ipv6=0 can be removed or set to 1 if there is no need for ipv6, no attempt will be made in that case to set ip6tables rules and can prevent an error if the module ip6table_filter isn't loaded on the host. The WireGuard configuration should not have any ipv6 related stuff when ipv6 is disabled, otherwise creating the interface will fail. If your vpn provider supports ipv6 and you keep it enabled, you'll have full ipv6 connectivity over the vpn connection (confirmed with Mullvad). If for any reason there's a failure trying to setup ip6tables rules, you'll probably need to do sudo modprobe ip6table_filter on the host, this will mostly happen on systems that have ipv6 completely disabled. The environment variable VPN_LAN_NETWORK can be set to for example 192.168.1.0/24 , 192.168.1.0/24,192.168.44.0/24 or 192.168.1.33 , so you can get access to the qBittorrent webui. If you need to expose additional ports you can use VPN_ADDITIONAL_PORTS , for example VPN_ADDITIONAL_PORTS=7878/tcp,9117/tcp . Every port in this list will be blocked on the vpn interface, so that there's no risk that they might be exposed to the world via the vpn (mostly there in case your vpn provider screws up and piece of mind). Why would you need this? Wanting to route traffic from other containers over the vpn is probably the most used scenario.","title":"WireGuard VPN support"},{"location":"containers/qflood/#wg0conf-example","text":"This is an example of how your wg0.conf could look like. [Interface] PrivateKey = supersecretprivatekey Address = xx.xx.xxx.xxx/32 DNS = 1.1.1.1 [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xxx.x.xxx.x:51820","title":"wg0.conf example"},{"location":"containers/qflood/#torguard-instructions","text":"While Mullvad is pretty straightforward to setup by using the wg0.conf example from above, TorGuard is a bit more complex. Our wg0.conf should look something like this: # TorGuard WireGuard Config [Interface] PrivateKey = secretprivatekey ListenPort = 51820 DNS = 1.1.1.1 Address = xx.xx.xxx.xx/24 PreUp = bash /config/wireguard/torguard.sh [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xx.xxx.xx.xxx:1443 PersistentKeepalive = 25 Pay attention to PreUp = bash /config/wireguard/torguard.sh in our config. That command will execute the below script that you should create in /config/wireguard/torguard.sh , this script will get executed just before starting WireGuard. 1 2 3 4 5 6 7 #!/usr/bin/bash pubkey = $( grep PrivateKey \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' | wg pubkey ) wgserver = $( grep Endpoint \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' ) curl -ksG -u \" ${ TORGUARD_USER } \" : \" ${ TORGUARD_PASS } \" \\ --data-urlencode \"public-key= ${ pubkey } \" \"https:// ${ wgserver } /api/v1/setup\" You will also have to add the additional environment variables TORGUARD_USER and TORGUARD_PASS or fill them in into the script directly (see curl command). These credentials can be found here . My experience with getting TorGuard working wasn't the smoothest journey to say the least. I had to click around quite a bit and finally after generating my 3rd config it worked. On the Netherlands server for example I didn't get any internet connectivity and at first I was unable to get port forwarding working on the Germany server. All of a sudden after generating the 3rd config and also pasting in the ip found under My Fixed IPs , that seems to populate when doing a Port Forward Request, I managed to get port forwarding working. So don't give up too soon, it can all work eventually.","title":"TorGuard instructions"},{"location":"containers/radarr/","text":"GitHub GitHub Registry Docker Hub Radarr Starting the container \u00b6 cli docker run --rm \\ --name radarr \\ -p 7878 :7878 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/radarr compose version : \"3.7\" services : radarr : container_name : radarr image : hotio/radarr ports : - \"7878:7878\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) master testing develop nightly nightly musl nightly, runs on Alpine","title":"hotio/radarr"},{"location":"containers/radarr/#starting-the-container","text":"cli docker run --rm \\ --name radarr \\ -p 7878 :7878 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/radarr compose version : \"3.7\" services : radarr : container_name : radarr image : hotio/radarr ports : - \"7878:7878\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/radarr/#tags","text":"Tag Upstream Version Build release (latest) master testing develop nightly nightly musl nightly, runs on Alpine","title":"Tags"},{"location":"containers/rar2fs/","text":"GitHub GitHub Registry Docker Hub rar2fs Starting the container \u00b6 cli docker run --rm hotio/rar2fs ... The default ENTRYPOINT is rar2fs -f -o auto_unmount . Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases Using the rar2fs mount on the host \u00b6 By setting the bind-propagation to shared on the volume mountpoint , like this -v /data/mountpoint:/mountpoint:shared , you are able to access the mount from the host. If you want to use this mount in another container, the best solution is to create a volume on the parent folder of that mount with bind-propagation set to slave . For example, -v /data:/data:slave ( /data on the host, would contain the previously created volume mountpoint ). Doing it like this will ensure that when the container creating the mount restarts, the other containers using that mount will recover and keep working. Extra docker privileges \u00b6 In most cases you will need some or all of the following flags added to your command to get the required docker privileges when using a rar2fs mount. --security-opt apparmor:unconfined --cap-add SYS_ADMIN --device /dev/fuse","title":"hotio/rar2fs"},{"location":"containers/rar2fs/#starting-the-container","text":"cli docker run --rm hotio/rar2fs ... The default ENTRYPOINT is rar2fs -f -o auto_unmount .","title":"Starting the container"},{"location":"containers/rar2fs/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"Tags"},{"location":"containers/rar2fs/#using-the-rar2fs-mount-on-the-host","text":"By setting the bind-propagation to shared on the volume mountpoint , like this -v /data/mountpoint:/mountpoint:shared , you are able to access the mount from the host. If you want to use this mount in another container, the best solution is to create a volume on the parent folder of that mount with bind-propagation set to slave . For example, -v /data:/data:slave ( /data on the host, would contain the previously created volume mountpoint ). Doing it like this will ensure that when the container creating the mount restarts, the other containers using that mount will recover and keep working.","title":"Using the rar2fs mount on the host"},{"location":"containers/rar2fs/#extra-docker-privileges","text":"In most cases you will need some or all of the following flags added to your command to get the required docker privileges when using a rar2fs mount. --security-opt apparmor:unconfined --cap-add SYS_ADMIN --device /dev/fuse","title":"Extra docker privileges"},{"location":"containers/rclone/","text":"GitHub GitHub Registry Docker Hub Rclone Starting the container \u00b6 cli docker run --rm hotio/rclone ... The default ENTRYPOINT is rclone . Tags \u00b6 Tag Upstream Version Build release (latest) Releases testing Beta releases Using a rclone mount on the host \u00b6 By setting the bind-propagation to shared on the volume mountpoint , like this -v /data/mountpoint:/mountpoint:shared , you are able to access the mount from the host. If you want to use this mount in another container, the best solution is to create a volume on the parent folder of that mount with bind-propagation set to slave . For example, -v /data:/data:slave ( /data on the host, would contain the previously created volume mountpoint ). Doing it like this will ensure that when the container creating the mount restarts, the other containers using that mount will recover and keep working. Extra docker privileges \u00b6 In most cases you will need some or all of the following flags added to your command to get the required docker privileges when using rclone mount . --security-opt apparmor:unconfined --cap-add SYS_ADMIN --device /dev/fuse","title":"hotio/rclone"},{"location":"containers/rclone/#starting-the-container","text":"cli docker run --rm hotio/rclone ... The default ENTRYPOINT is rclone .","title":"Starting the container"},{"location":"containers/rclone/#tags","text":"Tag Upstream Version Build release (latest) Releases testing Beta releases","title":"Tags"},{"location":"containers/rclone/#using-a-rclone-mount-on-the-host","text":"By setting the bind-propagation to shared on the volume mountpoint , like this -v /data/mountpoint:/mountpoint:shared , you are able to access the mount from the host. If you want to use this mount in another container, the best solution is to create a volume on the parent folder of that mount with bind-propagation set to slave . For example, -v /data:/data:slave ( /data on the host, would contain the previously created volume mountpoint ). Doing it like this will ensure that when the container creating the mount restarts, the other containers using that mount will recover and keep working.","title":"Using a rclone mount on the host"},{"location":"containers/rclone/#extra-docker-privileges","text":"In most cases you will need some or all of the following flags added to your command to get the required docker privileges when using rclone mount . --security-opt apparmor:unconfined --cap-add SYS_ADMIN --device /dev/fuse","title":"Extra docker privileges"},{"location":"containers/readarr/","text":"GitHub GitHub Registry Docker Hub Readarr Warning Until further notice, some updates could require a fresh database. There's only a nightly tag available for the moment. Starting the container \u00b6 cli docker run --rm \\ --name readarr \\ -p 8787 :8787 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/readarr compose version : \"3.7\" services : readarr : container_name : readarr image : hotio/readarr ports : - \"8787:8787\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) not yet available testing not yet available nightly nightly","title":"hotio/readarr"},{"location":"containers/readarr/#starting-the-container","text":"cli docker run --rm \\ --name readarr \\ -p 8787 :8787 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/readarr compose version : \"3.7\" services : readarr : container_name : readarr image : hotio/readarr ports : - \"8787:8787\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/readarr/#tags","text":"Tag Upstream Version Build release (latest) not yet available testing not yet available nightly nightly","title":"Tags"},{"location":"containers/requestrr/","text":"GitHub GitHub Registry Docker Hub Requestrr Starting the container \u00b6 cli docker run --rm \\ --name requestrr \\ -p 4545 :4545 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/requestrr compose version : \"3.7\" services : requestrr : container_name : requestrr image : hotio/requestrr ports : - \"4545:4545\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases","title":"hotio/requestrr"},{"location":"containers/requestrr/#starting-the-container","text":"cli docker run --rm \\ --name requestrr \\ -p 4545 :4545 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/requestrr compose version : \"3.7\" services : requestrr : container_name : requestrr image : hotio/requestrr ports : - \"4545:4545\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config","title":"Starting the container"},{"location":"containers/requestrr/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"Tags"},{"location":"containers/restic/","text":"GitHub GitHub Registry Docker Hub Restic Starting the container \u00b6 cli docker run --rm hotio/restic ... The default ENTRYPOINT is restic . Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases","title":"hotio/restic"},{"location":"containers/restic/#starting-the-container","text":"cli docker run --rm hotio/restic ... The default ENTRYPOINT is restic .","title":"Starting the container"},{"location":"containers/restic/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases","title":"Tags"},{"location":"containers/rflood/","text":"GitHub GitHub Registry Docker Hub rTorrent Flood What is this? A docker image with rTorrent and the Flood UI, also optional WireGuard VPN support. Starting the container \u00b6 cli docker run --rm \\ --name rflood \\ -p 3000 :3000 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e FLOOD_AUTH = \"false\" \\ -v /<host_folder_config>:/config \\ hotio/rflood compose version : \"3.7\" services : rflood : container_name : rflood image : hotio/rflood ports : - \"3000:3000\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - FLOOD_AUTH=false volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) Releases WireGuard VPN support \u00b6 This is probably not going to work if your OS has no kernel with WireGuard support. Tested Operating Systems: Ubuntu 18.04 Ubuntu 20.04 Unraid 6.8.3 Unraid 6.9 RC2 macOS Big Sur 11.2.1 Apple M1 cli docker run --rm \\ --name rflood \\ -p 3000 :3000 \\ -p 8118 :8118 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e VPN_ENABLED = \"true\" \\ -e VPN_LAN_NETWORK = \"\" \\ -e VPN_CONF = \"wg0\" \\ -e VPN_ADDITIONAL_PORTS = \"\" \\ -e PRIVOXY_ENABLED = \"false\" \\ -e FLOOD_AUTH = \"false\" \\ -v /<host_folder_config>:/config \\ --cap-add = NET_ADMIN \\ --sysctl = \"net.ipv4.conf.all.src_valid_mark=1\" \\ --sysctl = \"net.ipv6.conf.all.disable_ipv6=0\" \\ hotio/rflood compose version : \"3.7\" services : rflood : container_name : rflood image : hotio/rflood ports : - \"3000:3000\" - \"8118:8118\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - VPN_ENABLED=true - VPN_LAN_NETWORK - VPN_CONF=wg0 - VPN_ADDITIONAL_PORTS - PRIVOXY_ENABLED=false - FLOOD_AUTH=false volumes : - /<host_folder_config>:/config cap_add : - NET_ADMIN sysctls : - net.ipv4.conf.all.src_valid_mark=1 - net.ipv6.conf.all.disable_ipv6=0 There needs to be a file wg0.conf located in /config/wireguard and you need to set the variable VPN_ENABLED to true for the VPN to start. The part with net.ipv6.conf.all.disable_ipv6=0 can be removed or set to 1 if there is no need for ipv6, no attempt will be made in that case to set ip6tables rules and can prevent an error if the module ip6table_filter isn't loaded on the host. The WireGuard configuration should not have any ipv6 related stuff when ipv6 is disabled, otherwise creating the interface will fail. If your vpn provider supports ipv6 and you keep it enabled, you'll have full ipv6 connectivity over the vpn connection (confirmed with Mullvad). If for any reason there's a failure trying to setup ip6tables rules, you'll probably need to do sudo modprobe ip6table_filter on the host, this will mostly happen on systems that have ipv6 completely disabled. The environment variable VPN_LAN_NETWORK can be set to for example 192.168.1.0/24 , 192.168.1.0/24,192.168.44.0/24 or 192.168.1.33 , so you can get access to the qBittorrent webui. If you need to expose additional ports you can use VPN_ADDITIONAL_PORTS , for example VPN_ADDITIONAL_PORTS=7878/tcp,9117/tcp . Every port in this list will be blocked on the vpn interface, so that there's no risk that they might be exposed to the world via the vpn (mostly there in case your vpn provider screws up and piece of mind). Why would you need this? Wanting to route traffic from other containers over the vpn is probably the most used scenario. wg0.conf example \u00b6 This is an example of how your wg0.conf could look like. [Interface] PrivateKey = supersecretprivatekey Address = xx.xx.xxx.xxx/32 DNS = 1.1.1.1 [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xxx.x.xxx.x:51820 TorGuard instructions \u00b6 While Mullvad is pretty straightforward to setup by using the wg0.conf example from above, TorGuard is a bit more complex. Our wg0.conf should look something like this: # TorGuard WireGuard Config [Interface] PrivateKey = secretprivatekey ListenPort = 51820 DNS = 1.1.1.1 Address = xx.xx.xxx.xx/24 PreUp = bash /config/wireguard/torguard.sh [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xx.xxx.xx.xxx:1443 PersistentKeepalive = 25 Pay attention to PreUp = bash /config/wireguard/torguard.sh in our config. That command will execute the below script that you should create in /config/wireguard/torguard.sh , this script will get executed just before starting WireGuard. 1 2 3 4 5 6 7 #!/usr/bin/bash pubkey = $( grep PrivateKey \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' | wg pubkey ) wgserver = $( grep Endpoint \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' ) curl -ksG -u \" ${ TORGUARD_USER } \" : \" ${ TORGUARD_PASS } \" \\ --data-urlencode \"public-key= ${ pubkey } \" \"https:// ${ wgserver } /api/v1/setup\" You will also have to add the additional environment variables TORGUARD_USER and TORGUARD_PASS or fill them in into the script directly (see curl command). These credentials can be found here . My experience with getting TorGuard working wasn't the smoothest journey to say the least. I had to click around quite a bit and finally after generating my 3rd config it worked. On the Netherlands server for example I didn't get any internet connectivity and at first I was unable to get port forwarding working on the Germany server. All of a sudden after generating the 3rd config and also pasting in the ip found under My Fixed IPs , that seems to populate when doing a Port Forward Request, I managed to get port forwarding working. So don't give up too soon, it can all work eventually.","title":"hotio/rflood"},{"location":"containers/rflood/#starting-the-container","text":"cli docker run --rm \\ --name rflood \\ -p 3000 :3000 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e FLOOD_AUTH = \"false\" \\ -v /<host_folder_config>:/config \\ hotio/rflood compose version : \"3.7\" services : rflood : container_name : rflood image : hotio/rflood ports : - \"3000:3000\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - FLOOD_AUTH=false volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/rflood/#tags","text":"Tag Upstream Version Build release (latest) Releases","title":"Tags"},{"location":"containers/rflood/#wireguard-vpn-support","text":"This is probably not going to work if your OS has no kernel with WireGuard support. Tested Operating Systems: Ubuntu 18.04 Ubuntu 20.04 Unraid 6.8.3 Unraid 6.9 RC2 macOS Big Sur 11.2.1 Apple M1 cli docker run --rm \\ --name rflood \\ -p 3000 :3000 \\ -p 8118 :8118 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e VPN_ENABLED = \"true\" \\ -e VPN_LAN_NETWORK = \"\" \\ -e VPN_CONF = \"wg0\" \\ -e VPN_ADDITIONAL_PORTS = \"\" \\ -e PRIVOXY_ENABLED = \"false\" \\ -e FLOOD_AUTH = \"false\" \\ -v /<host_folder_config>:/config \\ --cap-add = NET_ADMIN \\ --sysctl = \"net.ipv4.conf.all.src_valid_mark=1\" \\ --sysctl = \"net.ipv6.conf.all.disable_ipv6=0\" \\ hotio/rflood compose version : \"3.7\" services : rflood : container_name : rflood image : hotio/rflood ports : - \"3000:3000\" - \"8118:8118\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - VPN_ENABLED=true - VPN_LAN_NETWORK - VPN_CONF=wg0 - VPN_ADDITIONAL_PORTS - PRIVOXY_ENABLED=false - FLOOD_AUTH=false volumes : - /<host_folder_config>:/config cap_add : - NET_ADMIN sysctls : - net.ipv4.conf.all.src_valid_mark=1 - net.ipv6.conf.all.disable_ipv6=0 There needs to be a file wg0.conf located in /config/wireguard and you need to set the variable VPN_ENABLED to true for the VPN to start. The part with net.ipv6.conf.all.disable_ipv6=0 can be removed or set to 1 if there is no need for ipv6, no attempt will be made in that case to set ip6tables rules and can prevent an error if the module ip6table_filter isn't loaded on the host. The WireGuard configuration should not have any ipv6 related stuff when ipv6 is disabled, otherwise creating the interface will fail. If your vpn provider supports ipv6 and you keep it enabled, you'll have full ipv6 connectivity over the vpn connection (confirmed with Mullvad). If for any reason there's a failure trying to setup ip6tables rules, you'll probably need to do sudo modprobe ip6table_filter on the host, this will mostly happen on systems that have ipv6 completely disabled. The environment variable VPN_LAN_NETWORK can be set to for example 192.168.1.0/24 , 192.168.1.0/24,192.168.44.0/24 or 192.168.1.33 , so you can get access to the qBittorrent webui. If you need to expose additional ports you can use VPN_ADDITIONAL_PORTS , for example VPN_ADDITIONAL_PORTS=7878/tcp,9117/tcp . Every port in this list will be blocked on the vpn interface, so that there's no risk that they might be exposed to the world via the vpn (mostly there in case your vpn provider screws up and piece of mind). Why would you need this? Wanting to route traffic from other containers over the vpn is probably the most used scenario.","title":"WireGuard VPN support"},{"location":"containers/rflood/#wg0conf-example","text":"This is an example of how your wg0.conf could look like. [Interface] PrivateKey = supersecretprivatekey Address = xx.xx.xxx.xxx/32 DNS = 1.1.1.1 [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xxx.x.xxx.x:51820","title":"wg0.conf example"},{"location":"containers/rflood/#torguard-instructions","text":"While Mullvad is pretty straightforward to setup by using the wg0.conf example from above, TorGuard is a bit more complex. Our wg0.conf should look something like this: # TorGuard WireGuard Config [Interface] PrivateKey = secretprivatekey ListenPort = 51820 DNS = 1.1.1.1 Address = xx.xx.xxx.xx/24 PreUp = bash /config/wireguard/torguard.sh [Peer] PublicKey = publickey AllowedIPs = 0.0.0.0/0 Endpoint = xx.xxx.xx.xxx:1443 PersistentKeepalive = 25 Pay attention to PreUp = bash /config/wireguard/torguard.sh in our config. That command will execute the below script that you should create in /config/wireguard/torguard.sh , this script will get executed just before starting WireGuard. 1 2 3 4 5 6 7 #!/usr/bin/bash pubkey = $( grep PrivateKey \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' | wg pubkey ) wgserver = $( grep Endpoint \" ${ CONFIG_DIR } /wireguard/wg0.conf\" | awk '{print $3}' ) curl -ksG -u \" ${ TORGUARD_USER } \" : \" ${ TORGUARD_PASS } \" \\ --data-urlencode \"public-key= ${ pubkey } \" \"https:// ${ wgserver } /api/v1/setup\" You will also have to add the additional environment variables TORGUARD_USER and TORGUARD_PASS or fill them in into the script directly (see curl command). These credentials can be found here . My experience with getting TorGuard working wasn't the smoothest journey to say the least. I had to click around quite a bit and finally after generating my 3rd config it worked. On the Netherlands server for example I didn't get any internet connectivity and at first I was unable to get port forwarding working on the Germany server. All of a sudden after generating the 3rd config and also pasting in the ip found under My Fixed IPs , that seems to populate when doing a Port Forward Request, I managed to get port forwarding working. So don't give up too soon, it can all work eventually.","title":"TorGuard instructions"},{"location":"containers/sabnzbd/","text":"GitHub GitHub Registry Docker Hub SABnzbd Starting the container \u00b6 cli docker run --rm \\ --name sabnzbd \\ -p 8080 :8080 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/sabnzbd compose version : \"3.7\" services : sabnzbd : container_name : sabnzbd image : hotio/sabnzbd ports : - \"8080:8080\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases nightly Every commit to develop branch","title":"hotio/sabnzbd"},{"location":"containers/sabnzbd/#starting-the-container","text":"cli docker run --rm \\ --name sabnzbd \\ -p 8080 :8080 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/sabnzbd compose version : \"3.7\" services : sabnzbd : container_name : sabnzbd image : hotio/sabnzbd ports : - \"8080:8080\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/sabnzbd/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases nightly Every commit to develop branch","title":"Tags"},{"location":"containers/scrutiny/","text":"GitHub GitHub Registry Docker Hub Scrutiny Starting the container \u00b6 cli docker run --rm \\ --name scrutiny \\ -p 8080 :8080 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e INTERVAL = 86400 \\ -e API_ENDPOINT = \"http://localhost:8080\" \\ -e MODE = \"both\" \\ -v /<host_folder_config>:/config \\ -v /run/udev:/run/udev:ro \\ --cap-add SYS_RAWIO \\ --device /dev/sda \\ hotio/scrutiny compose version : \"3.7\" services : scrutiny : container_name : scrutiny image : hotio/scrutiny ports : - \"8080:8080\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - INTERVAL=86400 - API_ENDPOINT=http://localhost:8080 - MODE=both volumes : - /<host_folder_config>:/config - /run/udev:/run/udev:ro cap_add : - SYS_RAWIO devices : - /dev/sda For the environment variable MODE you can pick the values both , web or collector to enable the desired operating mode (see below). The INTERVAL variable defines the amount of time in seconds between collector runs, the metrics are pushed to the webinterface located at API_ENDPOINT . When passing through NVMe devices you'll probably have to use --cap-add SYS_ADMIN and/or --cap-add SYS_RAWIO . Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch Deploying as 2 seperate containers \u00b6 cli docker run --rm \\ --name scrutiny-collector \\ --network my-net \\ -e INTERVAL = 3600 \\ -e API_ENDPOINT = \"http://scrutiny-web:8080\" \\ -e MODE = \"collector\" \\ -v /<host_folder_config>:/config \\ -v /run/udev:/run/udev:ro \\ --cap-add SYS_RAWIO \\ --device /dev/sda \\ hotio/scrutiny docker run --rm \\ --name scrutiny-web \\ --network my-net \\ -p 8080 :8080 \\ -e MODE = \"web\" \\ -v /<host_folder_config>:/config \\ hotio/scrutiny compose version : \"3.7\" services : scrutiny-collector : container_name : scrutiny-collector image : hotio/scrutiny environment : - INTERVAL=3600 - API_ENDPOINT=http://scrutiny-web:8080 - MODE=collector volumes : - /<host_folder_config>:/config - /run/udev:/run/udev:ro cap_add : - SYS_RAWIO devices : - /dev/sda scrutiny-web : container_name : scrutiny-web image : hotio/scrutiny ports : - \"8080:8080\" environment : - MODE=web volumes : - /<host_folder_config>:/config","title":"hotio/scrutiny"},{"location":"containers/scrutiny/#starting-the-container","text":"cli docker run --rm \\ --name scrutiny \\ -p 8080 :8080 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -e INTERVAL = 86400 \\ -e API_ENDPOINT = \"http://localhost:8080\" \\ -e MODE = \"both\" \\ -v /<host_folder_config>:/config \\ -v /run/udev:/run/udev:ro \\ --cap-add SYS_RAWIO \\ --device /dev/sda \\ hotio/scrutiny compose version : \"3.7\" services : scrutiny : container_name : scrutiny image : hotio/scrutiny ports : - \"8080:8080\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC - INTERVAL=86400 - API_ENDPOINT=http://localhost:8080 - MODE=both volumes : - /<host_folder_config>:/config - /run/udev:/run/udev:ro cap_add : - SYS_RAWIO devices : - /dev/sda For the environment variable MODE you can pick the values both , web or collector to enable the desired operating mode (see below). The INTERVAL variable defines the amount of time in seconds between collector runs, the metrics are pushed to the webinterface located at API_ENDPOINT . When passing through NVMe devices you'll probably have to use --cap-add SYS_ADMIN and/or --cap-add SYS_RAWIO .","title":"Starting the container"},{"location":"containers/scrutiny/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases nightly Every commit to master branch","title":"Tags"},{"location":"containers/scrutiny/#deploying-as-2-seperate-containers","text":"cli docker run --rm \\ --name scrutiny-collector \\ --network my-net \\ -e INTERVAL = 3600 \\ -e API_ENDPOINT = \"http://scrutiny-web:8080\" \\ -e MODE = \"collector\" \\ -v /<host_folder_config>:/config \\ -v /run/udev:/run/udev:ro \\ --cap-add SYS_RAWIO \\ --device /dev/sda \\ hotio/scrutiny docker run --rm \\ --name scrutiny-web \\ --network my-net \\ -p 8080 :8080 \\ -e MODE = \"web\" \\ -v /<host_folder_config>:/config \\ hotio/scrutiny compose version : \"3.7\" services : scrutiny-collector : container_name : scrutiny-collector image : hotio/scrutiny environment : - INTERVAL=3600 - API_ENDPOINT=http://scrutiny-web:8080 - MODE=collector volumes : - /<host_folder_config>:/config - /run/udev:/run/udev:ro cap_add : - SYS_RAWIO devices : - /dev/sda scrutiny-web : container_name : scrutiny-web image : hotio/scrutiny ports : - \"8080:8080\" environment : - MODE=web volumes : - /<host_folder_config>:/config","title":"Deploying as 2 seperate containers"},{"location":"containers/sonarr/","text":"GitHub GitHub Registry Docker Hub Sonarr Starting the container \u00b6 cli docker run --rm \\ --name sonarr \\ -p 8989 :8989 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/sonarr compose version : \"3.7\" services : sonarr : container_name : sonarr image : hotio/sonarr ports : - \"8989:8989 environment: - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes: - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) master testing develop nightly phantom-develop","title":"hotio/sonarr"},{"location":"containers/sonarr/#starting-the-container","text":"cli docker run --rm \\ --name sonarr \\ -p 8989 :8989 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/sonarr compose version : \"3.7\" services : sonarr : container_name : sonarr image : hotio/sonarr ports : - \"8989:8989 environment: - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes: - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/sonarr/#tags","text":"Tag Upstream Version Build release (latest) master testing develop nightly phantom-develop","title":"Tags"},{"location":"containers/stash/","text":"GitHub GitHub Registry Docker Hub Stash Starting the container \u00b6 cli docker run --rm \\ --name stash \\ -p 9999 :9999 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/stash compose version : \"3.7\" services : stash : container_name : stash image : hotio/stash ports : - \"9999:9999\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files. Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases nightly GitHub latest_develop release","title":"hotio/stash"},{"location":"containers/stash/#starting-the-container","text":"cli docker run --rm \\ --name stash \\ -p 9999 :9999 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/stash compose version : \"3.7\" services : stash : container_name : stash image : hotio/stash ports : - \"9999:9999\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config In most cases you'll need to add additional volumes, depending on your own personal preference, to get access to your files.","title":"Starting the container"},{"location":"containers/stash/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases nightly GitHub latest_develop release","title":"Tags"},{"location":"containers/tautulli/","text":"GitHub GitHub Registry Docker Hub Tautulli Starting the container \u00b6 cli docker run --rm \\ --name tautulli \\ -p 8181 :8181 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/tautulli compose version : \"3.7\" services : tautulli : container_name : tautulli image : hotio/tautulli ports : - \"8181:8181\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"hotio/tautulli"},{"location":"containers/tautulli/#starting-the-container","text":"cli docker run --rm \\ --name tautulli \\ -p 8181 :8181 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/tautulli compose version : \"3.7\" services : tautulli : container_name : tautulli image : hotio/tautulli ports : - \"8181:8181\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config","title":"Starting the container"},{"location":"containers/tautulli/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases","title":"Tags"},{"location":"containers/trackarr/","text":"GitHub GitHub Registry Docker Hub Trackarr Starting the container \u00b6 cli docker run --rm \\ --name trackarr \\ -p 7337 :7337 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/trackarr compose version : \"3.7\" services : trackarr : container_name : trackarr image : hotio/trackarr ports : - \"7337:7337\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config Tags \u00b6 Tag Upstream Version Build release (latest) Releases nightly Every commit to develop branch","title":"hotio/trackarr"},{"location":"containers/trackarr/#starting-the-container","text":"cli docker run --rm \\ --name trackarr \\ -p 7337 :7337 \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/trackarr compose version : \"3.7\" services : trackarr : container_name : trackarr image : hotio/trackarr ports : - \"7337:7337\" environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config","title":"Starting the container"},{"location":"containers/trackarr/#tags","text":"Tag Upstream Version Build release (latest) Releases nightly Every commit to develop branch","title":"Tags"},{"location":"containers/unpackerr/","text":"GitHub GitHub Registry Docker Hub Unpackerr Starting the container \u00b6 cli docker run --rm \\ --name unpackerr \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/unpackerr compose version : \"3.7\" services : unpackerr : container_name : unpackerr image : hotio/unpackerr environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config Tags \u00b6 Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases nightly Every commit to master branch Configuration \u00b6 You can use docker environment variables or a configuration file that should be stored in /config/unpackerr.conf . Don't forget to mount your volume where Unpackerr should look to find your downloads. Take a look at the upstream project page for info on how to configure Unpackerr.","title":"hotio/unpackerr"},{"location":"containers/unpackerr/#starting-the-container","text":"cli docker run --rm \\ --name unpackerr \\ -e PUID = 1000 \\ -e PGID = 1000 \\ -e UMASK = 002 \\ -e TZ = \"Etc/UTC\" \\ -v /<host_folder_config>:/config \\ hotio/unpackerr compose version : \"3.7\" services : unpackerr : container_name : unpackerr image : hotio/unpackerr environment : - PUID=1000 - PGID=1000 - UMASK=002 - TZ=Etc/UTC volumes : - /<host_folder_config>:/config","title":"Starting the container"},{"location":"containers/unpackerr/#tags","text":"Tag Upstream Version Build release (latest) GitHub releases testing GitHub pre-releases nightly Every commit to master branch","title":"Tags"},{"location":"containers/unpackerr/#configuration","text":"You can use docker environment variables or a configuration file that should be stored in /config/unpackerr.conf . Don't forget to mount your volume where Unpackerr should look to find your downloads. Take a look at the upstream project page for info on how to configure Unpackerr.","title":"Configuration"}]}